{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607665fe",
   "metadata": {},
   "source": [
    "# Cuisine Classification ML Training Pipeline\n",
    "\n",
    "This notebook demonstrates the complete ML training pipeline for cuisine classification using the gold layer data from our medallion architecture. It follows Databricks MLflow best practices for experiment tracking, model registration, and serving.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Data Preparation**: Load gold layer datasets with feature vectors\n",
    "2. **Model Training**: Fine-tune ResNet-50 for cuisine classification  \n",
    "3. **MLflow Integration**: Track experiments and register models\n",
    "4. **Model Serving**: Deploy model for real-time inference\n",
    "5. **Batch Inference**: Process new images with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2460232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for ML training\n",
    "%pip install datasets==2.20.0 transformers==4.49.0 tf-keras==2.17.0 accelerate==1.4.0 mlflow==2.20.2 torchvision==0.20.1 deepspeed==0.14.4\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af11936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor, AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline, DefaultDataCollator, EarlyStoppingCallback\n",
    "from PIL import Image\n",
    "import io\n",
    "from torchvision.transforms import CenterCrop, Compose, Normalize, RandomResizedCrop, Resize, ToTensor, Lambda\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from typing import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "CATALOG = \"cuisine_vision_catalog\"\n",
    "GOLD_SCHEMA = \"gold\"\n",
    "IMAGE_SIZE = 224\n",
    "MODEL_CHECKPOINT = \"microsoft/resnet-50\"\n",
    "EXPERIMENT_NAME = \"/Users/databricks/cuisine-classification-pipeline\"\n",
    "\n",
    "print(\"ğŸš€ Starting Cuisine Classification ML Pipeline\")\n",
    "print(f\"ğŸ“Š Using catalog: {CATALOG}\")\n",
    "print(f\"ğŸ¥‡ Gold schema: {GOLD_SCHEMA}\")\n",
    "print(f\"ğŸ–¼ï¸ Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"ğŸ§  Base model: {MODEL_CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1ae42",
   "metadata": {},
   "source": [
    "## 1. Data Preparation from Gold Layer\n",
    "Load the ML-ready dataset with proper stratified splits and feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da357f",
   "metadata": {},
   "source": [
    "## 1.1 Feature Store Setup\n",
    "Setup Databricks Feature Store for advanced feature management and discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Databricks Feature Store for advanced feature management\n",
    "from databricks.feature_store import FeatureStoreClient, FeatureLookup\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Feature Store client\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# Feature Store configuration\n",
    "FEATURE_STORE_SCHEMA = \"cuisine_vision_catalog.features\"\n",
    "FEATURE_TABLE_NAME = f\"{FEATURE_STORE_SCHEMA}.image_features\"\n",
    "\n",
    "print(\"ğŸª Setting up Databricks Feature Store...\")\n",
    "print(f\"   ğŸ“Š Feature table: {FEATURE_TABLE_NAME}\")\n",
    "\n",
    "def setup_feature_store():\n",
    "    \"\"\"One-time setup: Create Feature Store table from gold layer features\"\"\"\n",
    "    try:\n",
    "        # Read feature vectors from gold layer\n",
    "        feature_df = spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.feature_vectors\")\n",
    "        \n",
    "        print(f\"ğŸ“Š Creating Feature Store table: {FEATURE_TABLE_NAME}\")\n",
    "        \n",
    "        # Create feature table (ONE-TIME OPERATION)\n",
    "        fs.create_feature_table(\n",
    "            name=FEATURE_TABLE_NAME,\n",
    "            primary_keys=[\"image_id\"],\n",
    "            df=feature_df.limit(1),  # Just for schema inference\n",
    "            description=\"Advanced image feature vectors for cuisine classification ML models\",\n",
    "            tags={\n",
    "                \"team\": \"data-science\",\n",
    "                \"use_case\": \"cuisine_classification\", \n",
    "                \"feature_type\": \"image_features\",\n",
    "                \"version\": \"v1\",\n",
    "                \"pipeline\": \"cuisine_vision_dlt\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Feature Store table created: {FEATURE_TABLE_NAME}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if \"already exists\" in str(e).lower():\n",
    "            print(f\"â„¹ï¸  Feature table already exists: {FEATURE_TABLE_NAME}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ Error creating feature table: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "def update_feature_store():\n",
    "    \"\"\"Update Feature Store with latest feature data\"\"\"\n",
    "    try:\n",
    "        # Read latest feature vectors\n",
    "        feature_df = spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.feature_vectors\")\n",
    "        \n",
    "        print(f\"ğŸ”„ Updating Feature Store with {feature_df.count()} feature records...\")\n",
    "        \n",
    "        # Write features to Feature Store\n",
    "        fs.write_table(\n",
    "            name=FEATURE_TABLE_NAME,\n",
    "            df=feature_df,\n",
    "            mode=\"overwrite\"  # Use 'merge' for incremental updates\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Feature Store updated successfully!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error updating Feature Store: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Setup Feature Store (run once)\n",
    "if setup_feature_store():\n",
    "    update_feature_store()\n",
    "    print(\"\\nğŸª Feature Store Benefits:\")\n",
    "    print(\"   ğŸ“ˆ Feature Discovery: Browse features in Databricks UI\")\n",
    "    print(\"   ğŸ”— Feature Lineage: Track feature origin and transformations\")\n",
    "    print(\"   âš¡ Feature Serving: Fast feature lookups for inference\") \n",
    "    print(\"   ğŸ”„ Feature Reuse: Share features across ML teams\")\n",
    "    print(\"   ğŸ“Š Feature Monitoring: Track feature drift and quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold layer ML dataset\n",
    "print(\"ğŸ“‹ Loading gold layer ML dataset...\")\n",
    "\n",
    "ml_dataset = spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.ml_dataset\")\n",
    "# feature_vectors = spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.feature_vectors\")  # Optional for advanced features\n",
    "\n",
    "print(f\"âœ… Dataset loaded:\")\n",
    "print(f\"   ğŸ“Š Total records: {ml_dataset.count()}\")\n",
    "print(f\"   ğŸŒ Unique cuisines: {ml_dataset.select('cuisine_category').distinct().count()}\")\n",
    "print(f\"   ğŸ½ï¸ Unique food types: {ml_dataset.select('food_type').distinct().count()}\")\n",
    "\n",
    "# Show dataset distribution\n",
    "print(\"\\nğŸ“ˆ Dataset split distribution:\")\n",
    "ml_dataset.groupBy(\"dataset_split\", \"cuisine_category\").count().orderBy(\"cuisine_category\", \"dataset_split\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Use Feature Store for training (enhanced features)\n",
    "print(\"ğŸª Feature Store Integration Option...\")\n",
    "\n",
    "try:\n",
    "    # Create training set with Feature Store lookups\n",
    "    # Get base data with labels and image_id\n",
    "    base_training_df = (\n",
    "        spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.ml_dataset\")\n",
    "        .filter(col(\"dataset_split\") == \"train\")\n",
    "        .select(\"image_id\", \"cuisine_category\", \"processed_image_data\")\n",
    "    )\n",
    "    \n",
    "    # Create Feature Store training set\n",
    "    feature_lookups = [\n",
    "        FeatureLookup(\n",
    "            table_name=FEATURE_TABLE_NAME,\n",
    "            lookup_key=\"image_id\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    training_set = fs.create_training_set(\n",
    "        df=base_training_df,\n",
    "        feature_lookups=feature_lookups,\n",
    "        label=\"cuisine_category\"\n",
    "    )\n",
    "    \n",
    "    # Get enhanced training dataframe with features\n",
    "    enhanced_training_df = training_set.load_df()\n",
    "    \n",
    "    print(\"âœ… Feature Store training set created!\")\n",
    "    print(f\"   ğŸ“Š Features available: {len(enhanced_training_df.columns)} columns\")\n",
    "    print(f\"   ğŸ§  100D feature vector: feature_vector_v1\")\n",
    "    print(f\"   ğŸ¨ Color features: color_histogram, dominant_colors, etc.\")\n",
    "    print(f\"   ğŸ”² Texture features: edge_density, texture_contrast, etc.\")\n",
    "    print(f\"   ğŸ“ Shape features: symmetry_score, structural_complexity\")\n",
    "    \n",
    "    use_feature_store = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  Feature Store not available, using standard approach: {str(e)}\")\n",
    "    use_feature_store = False\n",
    "\n",
    "if not use_feature_store:\n",
    "    print(\"ğŸ“Š Using standard gold layer data...\")\n",
    "    # Fallback to standard approach\n",
    "    enhanced_training_df = ml_dataset.filter(col(\"dataset_split\") == \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f819d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data with proper format for HuggingFace\n",
    "print(\"ğŸ”„ Preparing training data for HuggingFace...\")\n",
    "\n",
    "# Select training data with images and labels\n",
    "training_data = (\n",
    "    ml_dataset\n",
    "    .filter(col(\"dataset_split\") == \"train\")\n",
    "    .select(\"image_id\", \"processed_image_data\", \"cuisine_category\", \"cuisine_category_encoded\", \"food_type\")\n",
    "    .filter(col(\"processed_image_data\").isNotNull())\n",
    ")\n",
    "\n",
    "validation_data = (\n",
    "    ml_dataset\n",
    "    .filter(col(\"dataset_split\") == \"validation\") \n",
    "    .select(\"image_id\", \"processed_image_data\", \"cuisine_category\", \"cuisine_category_encoded\", \"food_type\")\n",
    "    .filter(col(\"processed_image_data\").isNotNull())\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    ml_dataset\n",
    "    .filter(col(\"dataset_split\") == \"test\")\n",
    "    .select(\"image_id\", \"processed_image_data\", \"cuisine_category\", \"cuisine_category_encoded\", \"food_type\") \n",
    "    .filter(col(\"processed_image_data\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data splits prepared:\")\n",
    "print(f\"   ğŸ‹ï¸ Training: {training_data.count()} samples\")\n",
    "print(f\"   âœ… Validation: {validation_data.count()} samples\") \n",
    "print(f\"   ğŸ§ª Test: {test_data.count()} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HuggingFace Dataset format\n",
    "print(\"ğŸ¤— Converting to HuggingFace Dataset format...\")\n",
    "\n",
    "# Convert Spark DataFrames to HuggingFace Datasets\n",
    "train_dataset = Dataset.from_spark(\n",
    "    training_data, \n",
    "    cache_dir=\"/tmp/hf_cache/train\"\n",
    ").rename_column(\"processed_image_data\", \"image\").rename_column(\"cuisine_category\", \"label\")\n",
    "\n",
    "val_dataset = Dataset.from_spark(\n",
    "    validation_data,\n",
    "    cache_dir=\"/tmp/hf_cache/val\"\n",
    ").rename_column(\"processed_image_data\", \"image\").rename_column(\"cuisine_category\", \"label\")\n",
    "\n",
    "test_dataset = Dataset.from_spark(\n",
    "    test_data,\n",
    "    cache_dir=\"/tmp/hf_cache/test\"  \n",
    ").rename_column(\"processed_image_data\", \"image\").rename_column(\"cuisine_category\", \"label\")\n",
    "\n",
    "print(f\"âœ… HuggingFace datasets created:\")\n",
    "print(f\"   ğŸ“Š Training features: {train_dataset.features}\")\n",
    "print(f\"   ğŸ“ˆ Training samples: {len(train_dataset)}\")\n",
    "print(f\"   ğŸ“ˆ Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a35ab",
   "metadata": {},
   "source": [
    "## 2. Model Setup and Preprocessing\n",
    "Setup the ResNet-50 model for fine-tuning with proper preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model and preprocessing\n",
    "print(\"ğŸ§  Setting up model and preprocessing...\")\n",
    "\n",
    "# Load feature extractor for preprocessing\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "# Define image transformations\n",
    "transforms = Compose([\n",
    "    Lambda(lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")),  # Byte to PIL\n",
    "    ToTensor(),  # Convert PIL to tensor\n",
    "    Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "def preprocess_images(batch):\n",
    "    \"\"\"Apply transformations to image batch\"\"\"\n",
    "    batch[\"image\"] = [transforms(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# Apply transformations\n",
    "train_dataset.set_transform(preprocess_images)\n",
    "val_dataset.set_transform(preprocess_images)\n",
    "test_dataset.set_transform(preprocess_images)\n",
    "\n",
    "print(\"âœ… Preprocessing setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mappings for model\n",
    "print(\"ğŸ·ï¸ Creating label mappings...\")\n",
    "\n",
    "# Get unique labels and create mappings\n",
    "all_labels = set(train_dataset['label']) | set(val_dataset['label'])\n",
    "label2id = {label: i for i, label in enumerate(sorted(all_labels))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(f\"âœ… Label mappings created:\")\n",
    "print(f\"   ğŸ·ï¸ Total classes: {len(label2id)}\")\n",
    "print(f\"   ğŸŒ Cuisines: {list(label2id.keys())}\")\n",
    "\n",
    "# Load model with proper configuration\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    num_labels=len(label2id),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cd543",
   "metadata": {},
   "source": [
    "## 3. MLflow Experiment Setup\n",
    "Configure MLflow for experiment tracking and model management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow experiment\n",
    "print(\"ğŸ§ª Setting up MLflow experiment...\")\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "print(f\"âœ… MLflow experiment setup:\")\n",
    "print(f\"   ğŸ§ª Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"   ğŸ“Š Registry: databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e5e1d",
   "metadata": {},
   "source": [
    "## 4. Model Training with MLflow Tracking\n",
    "Train the model with comprehensive experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84600247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "model_name = MODEL_CHECKPOINT.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/tmp/huggingface/cuisine/{model_name}-finetuned\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='/tmp/logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True  # Use mixed precision for faster training\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Training configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model wrapper for MLflow\n",
    "class CuisineClassifierWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.pipeline.model.eval()\n",
    "\n",
    "    def predict(self, context, images):\n",
    "        \"\"\"Predict cuisine category from image binary data\"\"\"\n",
    "        from PIL import Image\n",
    "        import pandas as pd\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Convert binary data to PIL images\n",
    "            if 'processed_image_data' in images.columns:\n",
    "                pil_images = images['processed_image_data'].apply(\n",
    "                    lambda b: Image.open(io.BytesIO(b)) if b is not None else None\n",
    "                ).tolist()\n",
    "            else:\n",
    "                pil_images = images['image'].apply(\n",
    "                    lambda b: Image.open(io.BytesIO(b)) if b is not None else None\n",
    "                ).tolist()\n",
    "            \n",
    "            # Filter out None images\n",
    "            valid_images = [img for img in pil_images if img is not None]\n",
    "            \n",
    "            if not valid_images:\n",
    "                return pd.DataFrame([{'label': 'unknown', 'score': 0.0}])\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = self.pipeline(valid_images)\n",
    "            \n",
    "            # Return top prediction for each image\n",
    "            results = []\n",
    "            for pred in predictions:\n",
    "                if isinstance(pred, list):\n",
    "                    top_pred = max(pred, key=lambda x: x['score'])\n",
    "                else:\n",
    "                    top_pred = pred\n",
    "                results.append(top_pred)\n",
    "            \n",
    "            return pd.DataFrame(results)\n",
    "\n",
    "print(\"âœ… Model wrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow run and train model\n",
    "print(\"ğŸš€ Starting model training with MLflow tracking...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"cuisine-classification-resnet50\") as run:\n",
    "    # Log dataset information\n",
    "    mlflow.log_input(mlflow.data.from_huggingface(train_dataset, \"training\"))\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_checkpoint\": MODEL_CHECKPOINT,\n",
    "        \"num_classes\": len(label2id),\n",
    "        \"image_size\": IMAGE_SIZE,\n",
    "        \"num_epochs\": training_args.num_train_epochs,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"train_samples\": len(train_dataset),\n",
    "        \"val_samples\": len(val_dataset),\n",
    "        \"test_samples\": len(test_dataset)\n",
    "    })\n",
    "    \n",
    "    # Custom data collator for multi-class classification\n",
    "    def collate_fn(examples):\n",
    "        import torch\n",
    "        pixel_values = torch.stack([e[\"image\"] for e in examples])\n",
    "        labels = torch.tensor([label2id[e[\"label\"]] for e in examples], dtype=torch.long)\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=feature_extractor,\n",
    "        data_collator=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"ğŸ‹ï¸ Training model...\")\n",
    "    train_results = trainer.train()\n",
    "    \n",
    "    # Log training metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_results.training_loss,\n",
    "        \"train_runtime\": train_results.metrics[\"train_runtime\"],\n",
    "        \"train_samples_per_second\": train_results.metrics[\"train_samples_per_second\"]\n",
    "    })\n",
    "    \n",
    "    # Create inference pipeline\n",
    "    classifier = pipeline(\n",
    "        \"image-classification\",\n",
    "        model=trainer.state.best_model_checkpoint,\n",
    "        tokenizer=feature_extractor\n",
    "    )\n",
    "    \n",
    "    # Test the wrapper and create signature\n",
    "    print(\"ğŸ§ª Testing model wrapper...\")\n",
    "    test_sample = test_data.limit(3).toPandas()\n",
    "    wrapped_model = CuisineClassifierWrapper(classifier)\n",
    "    test_predictions = wrapped_model.predict(None, test_sample)\n",
    "    \n",
    "    # Create MLflow signature\n",
    "    signature = infer_signature(test_sample, test_predictions)\n",
    "    \n",
    "    # Log the model\n",
    "    print(\"ğŸ“ Logging model to MLflow...\")\n",
    "    logged_model = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"cuisine_classifier\",\n",
    "        python_model=wrapped_model,\n",
    "        pip_requirements=mlflow.transformers.get_default_pip_requirements(model),\n",
    "        signature=signature,\n",
    "        registered_model_name=f\"{CATALOG}.{GOLD_SCHEMA}.cuisine_classifier\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Model training complete!\")\n",
    "    print(f\"   ğŸ“ Model URI: {logged_model.model_uri}\")\n",
    "    print(f\"   ğŸ†” Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc17d92",
   "metadata": {},
   "source": [
    "## 5. Model Registration and Serving Setup\n",
    "Register the model for production serving with proper versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model and set alias for serving\n",
    "print(\"ğŸ“‹ Registering model for serving...\")\n",
    "\n",
    "model_name = f\"{CATALOG}.{GOLD_SCHEMA}.cuisine_classifier\"\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the latest version and set production alias\n",
    "latest_version = client.get_latest_versions(model_name)[0]\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"prod\",\n",
    "    version=latest_version.version\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model registered:\")\n",
    "print(f\"   ğŸ·ï¸ Name: {model_name}\")\n",
    "print(f\"   ğŸ“ Version: {latest_version.version}\")\n",
    "print(f\"   ğŸš€ Alias: prod\")\n",
    "\n",
    "print(\"âœ… Model ready for serving via Databricks Model Serving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097da90f",
   "metadata": {},
   "source": [
    "## 6. Batch Inference and Evaluation  \n",
    "Run batch inference on test data and evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF for batch inference\n",
    "print(\"ğŸ”® Creating inference UDF...\")\n",
    "\n",
    "predict_cuisine_udf = mlflow.pyfunc.spark_udf(\n",
    "    spark, \n",
    "    model_uri=f\"models:/{model_name}@prod\"\n",
    ")\n",
    "\n",
    "# Get input columns for UDF\n",
    "input_columns = predict_cuisine_udf.metadata.get_input_schema().input_names()\n",
    "\n",
    "print(f\"âœ… Inference UDF created:\")\n",
    "print(f\"   ğŸ“Š Input columns: {input_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch inference on test data\n",
    "print(\"ğŸ§ª Running batch inference on test data...\")\n",
    "\n",
    "test_predictions = (\n",
    "    test_data\n",
    "    .withColumn(\"cuisine_prediction\", predict_cuisine_udf(*input_columns))\n",
    "    .select(\n",
    "        \"image_id\", \n",
    "        \"cuisine_category\", \n",
    "        \"food_type\",\n",
    "        col(\"cuisine_prediction.label\").alias(\"predicted_cuisine\"),\n",
    "        col(\"cuisine_prediction.score\").alias(\"confidence_score\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save predictions to gold layer\n",
    "test_predictions.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{GOLD_SCHEMA}.test_predictions\")\n",
    "\n",
    "print(\"âœ… Batch inference complete\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"ğŸ“Š Sample predictions:\")\n",
    "test_predictions.orderBy(col(\"confidence_score\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede53a88",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Metrics\n",
    "Calculate comprehensive evaluation metrics and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "print(\"ğŸ“ˆ Calculating evaluation metrics...\")\n",
    "\n",
    "# Convert to pandas for detailed analysis\n",
    "results_df = test_predictions.toPandas()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (results_df['cuisine_category'] == results_df['predicted_cuisine']).mean()\n",
    "print(f\"ğŸ¯ Overall Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Per-cuisine accuracy\n",
    "cuisine_accuracy = results_df.groupby('cuisine_category').apply(\n",
    "    lambda x: (x['cuisine_category'] == x['predicted_cuisine']).mean()\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nğŸŒ Per-Cuisine Accuracy:\")\n",
    "print(cuisine_accuracy)\n",
    "\n",
    "# Log metrics to MLflow\n",
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    for cuisine, acc in cuisine_accuracy.items():\n",
    "        mlflow.log_metric(f\"accuracy_{cuisine}\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072960e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "print(\"ğŸ“Š Creating confusion matrix...\")\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix = pd.crosstab(\n",
    "    results_df['cuisine_category'], \n",
    "    results_df['predicted_cuisine'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    confusion_matrix.iloc[:-1, :-1],  # Exclude margins\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=confusion_matrix.columns[:-1],\n",
    "    yticklabels=confusion_matrix.index[:-1]\n",
    ")\n",
    "plt.title('Cuisine Classification Confusion Matrix')\n",
    "plt.xlabel('Predicted Cuisine')\n",
    "plt.ylabel('Actual Cuisine')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as MLflow artifact\n",
    "confusion_matrix.to_csv(\"/tmp/confusion_matrix.csv\")\n",
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    mlflow.log_artifact(\"/tmp/confusion_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis by confidence score\n",
    "print(\"ğŸ¯ Analyzing performance by confidence score...\")\n",
    "\n",
    "# Confidence distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_df['confidence_score'], bins=20, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Model Confidence Scores')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy by confidence threshold\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "accuracy_by_threshold = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_conf_mask = results_df['confidence_score'] >= threshold\n",
    "    if high_conf_mask.sum() > 0:\n",
    "        high_conf_accuracy = (\n",
    "            results_df[high_conf_mask]['cuisine_category'] == \n",
    "            results_df[high_conf_mask]['predicted_cuisine']\n",
    "        ).mean()\n",
    "        accuracy_by_threshold.append({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': high_conf_accuracy,\n",
    "            'sample_count': high_conf_mask.sum(),\n",
    "            'coverage': high_conf_mask.mean()\n",
    "        })\n",
    "\n",
    "threshold_df = pd.DataFrame(accuracy_by_threshold)\n",
    "print(\"\\nğŸ“Š Accuracy vs Confidence Threshold:\")\n",
    "print(threshold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ba8bc",
   "metadata": {},
   "source": [
    "## 8. Production Inference Example\n",
    "Demonstrate real-time inference on new images from the gold layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference on new images\n",
    "print(\"ğŸ”® Running inference on sample images...\")\n",
    "\n",
    "# Get sample images from different cuisines\n",
    "sample_images = (\n",
    "    spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.ml_dataset\")\n",
    "    .filter(col(\"dataset_split\") == \"test\")\n",
    "    .groupBy(\"cuisine_category\")\n",
    "    .agg({\"*\": \"first\"})  # Get one sample per cuisine\n",
    "    .select(\"cuisine_category\", \"processed_image_data\", \"food_type\")\n",
    ")\n",
    "\n",
    "# Run inference\n",
    "sample_predictions = (\n",
    "    sample_images\n",
    "    .withColumn(\"cuisine_prediction\", predict_cuisine_udf(\"processed_image_data\"))\n",
    "    .select(\n",
    "        \"cuisine_category\",\n",
    "        \"food_type\", \n",
    "        col(\"cuisine_prediction.label\").alias(\"predicted_cuisine\"),\n",
    "        col(\"cuisine_prediction.score\").alias(\"confidence_score\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ğŸ§ª Sample inference results:\")\n",
    "sample_predictions.show()\n",
    "\n",
    "# Save sample predictions\n",
    "sample_predictions.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{GOLD_SCHEMA}.sample_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd5560",
   "metadata": {},
   "source": [
    "## 9. Pipeline Summary and Next Steps\n",
    "\n",
    "### âœ… Completed Tasks\n",
    "- **Data Pipeline**: Complete medallion architecture (Bronze â†’ Silver â†’ Gold)\n",
    "- **Feature Engineering**: 100D feature vectors with advanced image analysis\n",
    "- **Feature Store**: Advanced features registered for ML discovery and reuse\n",
    "- **Model Training**: Fine-tuned ResNet-50 for cuisine classification\n",
    "- **MLflow Integration**: Experiment tracking and model registry\n",
    "- **Model Serving**: Production-ready model with inference UDF\n",
    "- **Evaluation**: Comprehensive performance metrics and visualizations\n",
    "\n",
    "### ğŸª Feature Store Integration\n",
    "- **Feature Discovery**: Browse all image features in Databricks UI catalog\n",
    "- **Feature Lineage**: Track how features are created from DLT pipeline\n",
    "- **Feature Serving**: Fast lookups for real-time inference\n",
    "- **Feature Reuse**: Share 100D vectors and color/texture features across teams\n",
    "- **Feature Monitoring**: Built-in drift detection and quality monitoring\n",
    "\n",
    "### ğŸš€ Next Steps\n",
    "1. **Model Serving Endpoint**: Deploy model to Databricks Model Serving\n",
    "2. **Real-time Inference**: Create REST API for real-time predictions with Feature Store lookups\n",
    "3. **Model Monitoring**: Set up drift detection and performance monitoring\n",
    "4. **A/B Testing**: Compare model versions for continuous improvement\n",
    "5. **Advanced Features**: Leverage Feature Store for feature experimentation and versioning\n",
    "\n",
    "### ğŸ¯ Production Architecture\n",
    "```\n",
    "HuggingFace â†’ DLT Pipeline â†’ Feature Store â†’ MLflow â†’ Model Serving\n",
    "    â†“              â†“             â†“           â†“           â†“\n",
    "Raw Images â†’ Gold Tables â†’ Features â†’ Models â†’ Inference\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final pipeline summary\n",
    "print(\"ğŸ‰ CUISINE CLASSIFICATION PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š Pipeline Summary:\")\n",
    "print(f\"   ğŸ¥‰ Bronze: Raw image data from HuggingFace\")\n",
    "print(f\"   ğŸ¥ˆ Silver: 8 cuisine tables with 224x224 processed images\") \n",
    "print(f\"   ğŸ¥‡ Gold: ML-ready datasets with 100D feature vectors\")\n",
    "print(f\"   ğŸ§  Model: Fine-tuned ResNet-50 for {len(label2id)} cuisines\")\n",
    "print(f\"   ğŸ¯ Accuracy: {accuracy:.1%}\")\n",
    "print(f\"   ğŸ“Š Test Samples: {len(results_df)}\")\n",
    "print(f\"   ğŸš€ Model: {model_name}@prod\")\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… Ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
