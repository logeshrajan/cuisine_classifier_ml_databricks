{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35dbc446-bc1a-4fc8-90ad-7dffe1f9d1a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple Cuisine Classification ML Training Pipeline\n",
    "\n",
    "A straightforward ML training pipeline for cuisine classification using ResNet-50.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Data Loading**: Load processed images from gold layer\n",
    "2. **Simple Preprocessing**: Convert bytes to PIL images with transforms\n",
    "3. **Model Training**: Fine-tune ResNet-50 using standard Transformers patterns\n",
    "4. **MLflow Integration**: Log and register model\n",
    "\n",
    "*Based on proven reference patterns - simple and reliable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a12d807-d7fd-4751-8ffa-33b0cc8ba9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.12/site-packages (2.7.0+cpu)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.12/site-packages (0.22.0+cpu)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.12/site-packages (4.51.3)\nRequirement already satisfied: datasets in /databricks/python3/lib/python3.12/site-packages (3.5.0)\nCollecting mlflow\n  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.6.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (4.12.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\nRequirement already satisfied: sympy>=1.13.3 in /databricks/python3/lib/python3.12/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.1.5)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch) (2023.5.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from torchvision) (2.1.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from torchvision) (11.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.12/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.12/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.12/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.11.10)\nCollecting mlflow-skinny==3.6.0 (from mlflow)\n  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.6.0 (from mlflow)\n  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: Flask<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.2.5)\nRequirement already satisfied: alembic!=1.10.0,<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.16.5)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (43.0.3)\nCollecting docker<8,>=4.0.0 (from mlflow)\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: gunicorn<24 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (20.1.0)\nCollecting huey<3,>=2.5.0 (from mlflow)\n  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.15.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.0.37)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.49.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.117.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.4)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.10.6)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)\n  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.4.2)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.37.0)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.4)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.40.3)\nRequirement already satisfied: starlette<0.49.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.21.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.27.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.14.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /databricks/python3/lib/python3.12/site-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.6.2)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.8)\nDownloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/8.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.9/8.9 MB\u001B[0m \u001B[31m84.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m56.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m35.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\nDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading huey-2.5.4-py3-none-any.whl (76 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\nDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nInstalling collected packages: huey, python-dotenv, opentelemetry-proto, graphql-relay, graphene, docker, Flask-CORS, mlflow-tracing, mlflow-skinny, mlflow\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 3.0.1\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-CORS-6.0.1 docker-7.1.0 graphene-3.4.3 graphql-relay-3.2.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-proto-1.38.0 python-dotenv-1.2.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Simple installation - only what we need\n",
    "%pip install torch torchvision transformers datasets mlflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a70ac9-7b92-4c75-b87c-c7b77bb6a4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2104df8-b767-4836-a237-558658b2e137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 09:31:03.415470: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-11-10 09:31:03.598520: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-11-10 09:31:03.781035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762767063.933936    1397 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762767064.049283    1397 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1762767064.325282    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762767064.325341    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762767064.325344    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762767064.325347    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-11-10 09:31:04.372984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-10 09:31:17,476] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n[2025-11-10 09:31:17,483] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\ncollect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Simple imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Simple imports - clean and minimal\n",
    "import mlflow\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from PIL import Image\n",
    "import io\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Lambda\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"✅ Simple imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4940f3b-d1aa-4780-8f10-64088a367589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Configuration:\n   \uD83D\uDCCA Catalog: cuisine_vision_catalog\n   \uD83E\uDDE0 Model: microsoft/resnet-50\n   \uD83D\uDD04 Epochs: 3\n   \uD83D\uDCE6 Batch Size: 8\n   \uD83D\uDCC8 Learning Rate: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Simple configuration - no complex widgets\n",
    "CATALOG = \"cuisine_vision_catalog\"\n",
    "MODEL_CHECKPOINT = \"microsoft/resnet-50\"\n",
    "EXPERIMENT_NAME = \"/cuisine_classifier\"\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "print(f\"\uD83D\uDD27 Configuration:\")\n",
    "print(f\"   \uD83D\uDCCA Catalog: {CATALOG}\")\n",
    "print(f\"   \uD83E\uDDE0 Model: {MODEL_CHECKPOINT}\")\n",
    "print(f\"   \uD83D\uDD04 Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   \uD83D\uDCE6 Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   \uD83D\uDCC8 Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1abd211-667b-4c89-9177-93bf97619294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Loading data from gold layer...\n✅ Loaded 1065 samples\n   \uD83C\uDF7D️ Cuisines: ['american', 'chinese', 'french', 'international', 'italian', 'japanese', 'mediterranean', 'mexican']\n✅ Data splits:\n   \uD83C\uDFCB️ Training: 852 samples\n   ✅ Validation: 213 samples\n"
     ]
    }
   ],
   "source": [
    "# Simple data loading - direct from gold table\n",
    "print(\"\uD83D\uDCCA Loading data from gold layer...\")\n",
    "\n",
    "# Load data directly - no complex joins\n",
    "dataset_df = (\n",
    "    spark.table(f\"{CATALOG}.gold.ml_dataset\")\n",
    "    .select(\"processed_image_data\", \"cuisine_category\")\n",
    "    .filter(\"processed_image_data IS NOT NULL\")\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "print(f\"✅ Loaded {len(dataset_df)} samples\")\n",
    "print(f\"   \uD83C\uDF7D️ Cuisines: {sorted(dataset_df['cuisine_category'].unique())}\")\n",
    "\n",
    "# Create HuggingFace dataset - simple rename\n",
    "dataset = Dataset.from_pandas(\n",
    "    dataset_df.rename(columns={\n",
    "        \"processed_image_data\": \"image\", \n",
    "        \"cuisine_category\": \"label\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# Simple train/test split\n",
    "splits = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "print(f\"✅ Data splits:\")\n",
    "print(f\"   \uD83C\uDFCB️ Training: {len(train_ds)} samples\")\n",
    "print(f\"   ✅ Validation: {len(val_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7520b2df-02bf-4f5d-b860-f0f2be6f82e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Setting up simple preprocessing...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b73db5a144243a5a8d1d8e3a27e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Simple preprocessing setup complete\n"
     ]
    }
   ],
   "source": [
    "# Simple preprocessing - exactly like reference notebook\n",
    "print(\"\uD83D\uDD04 Setting up simple preprocessing...\")\n",
    "\n",
    "# Load image processor\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "# Simple transform pipeline\n",
    "transforms = Compose([\n",
    "    Lambda(lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "def preprocess(batch):\n",
    "    \"\"\"Simple preprocessing function\"\"\"\n",
    "    batch[\"image\"] = [transforms(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# Apply transforms\n",
    "train_ds.set_transform(preprocess)\n",
    "val_ds.set_transform(preprocess)\n",
    "\n",
    "print(\"✅ Simple preprocessing setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae44bd2-527c-431f-a095-e007eee04889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83E\uDDE0 Setting up simple model...\n✅ Labels: {0: 'american', 1: 'chinese', 2: 'french', 3: 'international', 4: 'italian', 5: 'japanese', 6: 'mediterranean', 7: 'mexican'}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c2463ffa904423adac16bb64b7d770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562b98187b494e31b3e3d00ae5d24413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([8, 2048]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded with 8 classes\n"
     ]
    }
   ],
   "source": [
    "# Simple model setup - no complex wrappers\n",
    "print(\"\uD83E\uDDE0 Setting up simple model...\")\n",
    "\n",
    "# Create simple label mappings\n",
    "unique_labels = sorted(set(dataset['label']))\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "print(f\"✅ Labels: {id2label}\")\n",
    "\n",
    "# Load model - simple and direct\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Model loaded with {num_labels} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38f41cb8-f77b-43c1-aa77-c8e7703d7189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFCB️ Starting simple training...\n\uD83D\uDD04 MLflow run: 8cd6515b2c234a74a3b20d33448bed25\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/accelerate/state.py:261: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 4 to improve oob performance.\n  warnings.warn(\n/root/.ipykernel/1397/command-5371756412541010-2181546381:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 Training started...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n[rank0]:[W1110 09:43:33.286950767 reducer.cpp:1430] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [321/321 09:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.049300</td>\n",
       "      <td>2.027872</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.101408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.953300</td>\n",
       "      <td>2.013881</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.102548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>2.017588</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.102548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed!\n\uD83D\uDCCA Evaluating model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final metrics: {'eval_loss': 2.013880968093872, 'eval_accuracy': 0.2535211267605634, 'eval_f1': 0.10254787149865484, 'eval_runtime': 10.1883, 'eval_samples_per_second': 20.906, 'eval_steps_per_second': 2.65, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Simple training - no complex custom trainers\n",
    "print(\"\uD83C\uDFCB️ Starting simple training...\")\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"\uD83D\uDD04 MLflow run: {run.info.run_id}\")\n",
    "    \n",
    "    # Simple training arguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"/dbfs/tmp/cuisine-classifier-simple\",\n",
    "        remove_unused_columns=False,\n",
    "        eval_strategy=\"epoch\",  # Fixed: was evaluation_strategy\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        logging_steps=10,\n",
    "        report_to=[]\n",
    "    )\n",
    "    \n",
    "    # Simple data collator - like reference\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([e[\"image\"] for e in examples])\n",
    "        labels = torch.tensor([label2id[e[\"label\"]] for e in examples], dtype=torch.long)\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    \n",
    "    # Simple metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "        return {'accuracy': accuracy, 'f1': f1}\n",
    "    \n",
    "    # Simple trainer - standard Transformers\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        train_dataset=train_ds, \n",
    "        eval_dataset=val_ds, \n",
    "        tokenizer=image_processor, \n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\uD83D\uDE80 Training started...\")\n",
    "    trainer.train()\n",
    "    print(\"✅ Training completed!\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\uD83D\uDCCA Evaluating model...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"✅ Final metrics: {eval_results}\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_checkpoint\", MODEL_CHECKPOINT)\n",
    "    mlflow.log_param(\"num_epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"num_labels\", num_labels)\n",
    "    \n",
    "    # Log metrics\n",
    "    for key, value in eval_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            mlflow.log_metric(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2620520-0694-49fb-af2f-1e2ea07c5381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCE6 Creating simple model wrapper...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Simple model wrapper created\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "# Simple model wrapper for MLflow - like reference\n",
    "print(\"\uD83D\uDCE6 Creating simple model wrapper...\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create pipeline from trained model\n",
    "classifier = pipeline(\n",
    "    \"image-classification\", \n",
    "    model=trainer.model, \n",
    "    feature_extractor=image_processor\n",
    ")\n",
    "\n",
    "class SimpleCuisineClassifier(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Simple wrapper for cuisine classification - like reference notebook\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.pipeline.model.eval()\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"Simple prediction method\"\"\"\n",
    "        # Handle DataFrame input\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            # Convert bytes to PIL images\n",
    "            images = model_input['processed_image_data'].apply(\n",
    "                lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "            ).tolist()\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions = self.pipeline(images)\n",
    "            \n",
    "            # Return top prediction for each image\n",
    "            return pd.DataFrame([\n",
    "                max(pred, key=lambda x: x['score']) \n",
    "                for pred in predictions\n",
    "            ])\n",
    "        \n",
    "        # Handle single image bytes\n",
    "        else:\n",
    "            image = Image.open(io.BytesIO(model_input)).convert(\"RGB\")\n",
    "            with torch.no_grad():\n",
    "                prediction = self.pipeline(image)\n",
    "            return max(prediction, key=lambda x: x['score'])\n",
    "\n",
    "# Create wrapped model\n",
    "wrapped_model = SimpleCuisineClassifier(classifier)\n",
    "print(\"✅ Simple model wrapper created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c7f221-819e-4494-a5d8-ad556693d21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Logging model to MLflow...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 09:59:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test predictions:       label     score\n0  american  0.172005\n1  american  0.196499\n2  american  0.173358\n✅ Model signature created: inputs: \n  ['processed_image_data': binary (required)]\noutputs: \n  ['label': string (required), 'score': double (required)]\nparams: \n  None\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://adb-2867553723712000.0.azuredatabricks.net/ml/experiments/2328462332528265/models/m-7054c1d213f7468cb7dfc192bbf3fe68?o=2867553723712000\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3285: UserWarning: \u001B[1;33mAn input example was not provided when logging the model. To ensure the model signature functions correctly, specify the `input_example` parameter. See https://mlflow.org/docs/latest/model/signatures.html#model-input-example for more details about the benefits of using input_example.\u001B[0m\n  color_warning(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model logged with signature: models:/m-7054c1d213f7468cb7dfc192bbf3fe68\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'cuisine_vision_catalog.ml_models.cuisine_classifier_simple' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe27883a3804306a836ad1838a1edee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38e2cf074f4a56bead52902e10bbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '1' of model 'cuisine_vision_catalog.ml_models.cuisine_classifier_simple': https://adb-2867553723712000.0.azuredatabricks.net/explore/data/models/cuisine_vision_catalog/ml_models/cuisine_classifier_simple/version/1?o=2867553723712000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDF89 Model registered successfully!\n   \uD83D\uDCE6 Model: cuisine_vision_catalog.ml_models.cuisine_classifier_simple\n   \uD83C\uDFF7️ Version: 1\n   \uD83C\uDFAF Approach: Simple & Reliable\n"
     ]
    }
   ],
   "source": [
    "# Simple MLflow logging and registration\n",
    "print(\"\uD83D\uDCCA Logging model to MLflow...\")\n",
    "\n",
    "# Import signature utilities\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    # Test model with sample data and create signature\n",
    "    test_df = dataset_df[['processed_image_data']].head(3)\n",
    "    test_predictions = wrapped_model.predict(None, test_df)\n",
    "    print(f\"✅ Test predictions: {test_predictions}\")\n",
    "    \n",
    "    # Create model signature - required for Unity Catalog\n",
    "    signature = infer_signature(test_df, test_predictions)\n",
    "    print(f\"✅ Model signature created: {signature}\")\n",
    "    \n",
    "    # Log model with signature - required for Unity Catalog\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=wrapped_model,\n",
    "        signature=signature,  # Added signature for Unity Catalog\n",
    "        pip_requirements=[\n",
    "            \"torch\", \n",
    "            \"transformers\", \n",
    "            \"pillow\", \n",
    "            \"pandas\",\n",
    "            \"numpy\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Model logged with signature: {model_info.model_uri}\")\n",
    "\n",
    "# Register to Unity Catalog - simple registration\n",
    "full_model_name = f\"{CATALOG}.ml_models.cuisine_classifier_simple\"\n",
    "registered_model = mlflow.register_model(\n",
    "    model_uri=model_info.model_uri, \n",
    "    name=full_model_name,\n",
    "    tags={\n",
    "        \"stage\": \"development\",\n",
    "        \"task\": \"image_classification\",\n",
    "        \"architecture\": \"ResNet-50\",\n",
    "        \"approach\": \"simple\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\uD83C\uDF89 Model registered successfully!\")\n",
    "print(f\"   \uD83D\uDCE6 Model: {full_model_name}\")\n",
    "print(f\"   \uD83C\uDFF7️ Version: {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16601f9-746d-40f0-9040-48396a0ec995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83E\uDDEA Final testing...\nSample 31:\n   ✅ True: american\n   \uD83C\uDFAF Predicted: american (score: 0.209)\n\nSample 832:\n   ✅ True: japanese\n   \uD83C\uDFAF Predicted: american (score: 0.170)\n\nSample 413:\n   ✅ True: french\n   \uD83C\uDFAF Predicted: american (score: 0.169)\n\n\uD83C\uDF89 Simple pipeline completed successfully!\n\n\uD83D\uDCCB Summary:\n   \uD83D\uDCCA Total samples: 1065\n   \uD83C\uDFF7️ Classes: 8\n   \uD83D\uDD04 Epochs: 3\n   \uD83D\uDCE6 Model: cuisine_vision_catalog.ml_models.cuisine_classifier_simple v1\n   \uD83D\uDCA1 Approach: Clean, simple, and reliable!\n"
     ]
    }
   ],
   "source": [
    "# Simple testing - verify everything works\n",
    "print(\"\uD83E\uDDEA Final testing...\")\n",
    "\n",
    "# Test with a few samples\n",
    "test_samples = dataset_df.sample(n=3)\n",
    "for idx, row in test_samples.iterrows():\n",
    "    true_label = row['cuisine_category']\n",
    "    image_bytes = row['processed_image_data']\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = wrapped_model.predict(None, image_bytes)\n",
    "    \n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"   ✅ True: {true_label}\")\n",
    "    print(f\"   \uD83C\uDFAF Predicted: {prediction['label']} (score: {prediction['score']:.3f})\")\n",
    "    print()\n",
    "\n",
    "print(\"\uD83C\uDF89 Simple pipeline completed successfully!\")\n",
    "print(\"\\n\uD83D\uDCCB Summary:\")\n",
    "print(f\"   \uD83D\uDCCA Total samples: {len(dataset_df)}\")\n",
    "print(f\"   \uD83C\uDFF7️ Classes: {num_labels}\")\n",
    "print(f\"   \uD83D\uDD04 Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   \uD83D\uDCE6 Model: {full_model_name} v{registered_model.version}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML_Training_Pipeline_Simple",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}