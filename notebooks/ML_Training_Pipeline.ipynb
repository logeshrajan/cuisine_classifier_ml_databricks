{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35dbc446-bc1a-4fc8-90ad-7dffe1f9d1a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple Cuisine Classification ML Training Pipeline\n",
    "\n",
    "A straightforward ML training pipeline for cuisine classification using ResNet-50.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Data Loading**: Load processed images from gold layer\n",
    "2. **Simple Preprocessing**: Convert bytes to PIL images with transforms\n",
    "3. **Model Training**: Fine-tune ResNet-50 using standard Transformers patterns\n",
    "4. **MLflow Integration**: Log and register model\n",
    "\n",
    "*Based on proven reference patterns - simple and reliable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a12d807-d7fd-4751-8ffa-33b0cc8ba9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.12/site-packages (2.7.0+cpu)\n",
      "Requirement already satisfied: torchvision in /databricks/python3/lib/python3.12/site-packages (0.22.0+cpu)\n",
      "Requirement already satisfied: transformers in /databricks/python3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /databricks/python3/lib/python3.12/site-packages (3.5.0)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /databricks/python3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.11.10)\n",
      "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
      "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow)\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: Flask<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.2.5)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.16.5)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (43.0.3)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: gunicorn<24 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (20.1.0)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow)\n",
      "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (3.10.0)\n",
      "Requirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.15.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.0.37)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.0.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.49.0)\n",
      "Requirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.117.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.6.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.10.6)\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.37.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: Mako in /databricks/python3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.4)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\n",
      "Requirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.40.3)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.14.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /databricks/python3/lib/python3.12/site-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.8)\n",
      "Downloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/8.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: huey, python-dotenv, opentelemetry-proto, graphql-relay, graphene, docker, Flask-CORS, mlflow-tracing, mlflow-skinny, mlflow\n",
      "  Attempting uninstall: mlflow-skinny\n",
      "    Found existing installation: mlflow-skinny 3.0.1\n",
      "    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c\n",
      "    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\n",
      "Successfully installed Flask-CORS-6.0.1 docker-7.1.0 graphene-3.4.3 graphql-relay-3.2.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-proto-1.38.0 python-dotenv-1.2.1\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Simple installation - only what we need\n",
    "%pip install torch torchvision transformers datasets mlflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a70ac9-7b92-4c75-b87c-c7b77bb6a4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2104df8-b767-4836-a237-558658b2e137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 09:31:03.415470: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-10 09:31:03.598520: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-10 09:31:03.781035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762767063.933936    1397 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762767064.049283    1397 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762767064.325282    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762767064.325341    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762767064.325344    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762767064.325347    1397 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-10 09:31:04.372984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-10 09:31:17,476] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-11-10 09:31:17,483] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Simple imports - clean and minimal\n",
    "import mlflow\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from PIL import Image\n",
    "import io\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Lambda\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"âœ… Simple imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4940f3b-d1aa-4780-8f10-64088a367589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuration:\n",
      "   ğŸ“Š Catalog: cuisine_vision_catalog\n",
      "   ğŸ§  Model: microsoft/resnet-50\n",
      "   ğŸ”„ Epochs: 3\n",
      "   ğŸ“¦ Batch Size: 8\n",
      "   ğŸ“ˆ Learning Rate: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Simple configuration - no complex widgets\n",
    "CATALOG = \"cuisine_vision_catalog\"\n",
    "MODEL_CHECKPOINT = \"microsoft/resnet-50\"\n",
    "EXPERIMENT_NAME = \"/cuisine_classifier\"\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "print(f\"ğŸ”§ Configuration:\")\n",
    "print(f\"   ğŸ“Š Catalog: {CATALOG}\")\n",
    "print(f\"   ğŸ§  Model: {MODEL_CHECKPOINT}\")\n",
    "print(f\"   ğŸ”„ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   ğŸ“¦ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   ğŸ“ˆ Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1abd211-667b-4c89-9177-93bf97619294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading data from gold layer...\n",
      "âœ… Loaded 1065 samples\n",
      "   ğŸ½ï¸ Cuisines: ['american', 'chinese', 'french', 'international', 'italian', 'japanese', 'mediterranean', 'mexican']\n",
      "âœ… Data splits:\n",
      "   ğŸ‹ï¸ Training: 852 samples\n",
      "   âœ… Validation: 213 samples\n"
     ]
    }
   ],
   "source": [
    "# Simple data loading - direct from gold table\n",
    "print(\"ğŸ“Š Loading data from gold layer...\")\n",
    "\n",
    "# Load data directly - no complex joins\n",
    "dataset_df = (\n",
    "    spark.table(f\"{CATALOG}.gold.ml_dataset\")\n",
    "    .select(\"processed_image_data\", \"cuisine_category\")\n",
    "    .filter(\"processed_image_data IS NOT NULL\")\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "print(f\"âœ… Loaded {len(dataset_df)} samples\")\n",
    "print(f\"   ğŸ½ï¸ Cuisines: {sorted(dataset_df['cuisine_category'].unique())}\")\n",
    "\n",
    "# Create HuggingFace dataset - simple rename\n",
    "dataset = Dataset.from_pandas(\n",
    "    dataset_df.rename(columns={\n",
    "        \"processed_image_data\": \"image\", \n",
    "        \"cuisine_category\": \"label\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# Simple train/test split\n",
    "splits = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "print(f\"âœ… Data splits:\")\n",
    "print(f\"   ğŸ‹ï¸ Training: {len(train_ds)} samples\")\n",
    "print(f\"   âœ… Validation: {len(val_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7520b2df-02bf-4f5d-b860-f0f2be6f82e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Setting up simple preprocessing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b73db5a144243a5a8d1d8e3a27e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple preprocessing setup complete\n"
     ]
    }
   ],
   "source": [
    "# Simple preprocessing - exactly like reference notebook\n",
    "print(\"ğŸ”„ Setting up simple preprocessing...\")\n",
    "\n",
    "# Load image processor\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "# Simple transform pipeline\n",
    "transforms = Compose([\n",
    "    Lambda(lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "def preprocess(batch):\n",
    "    \"\"\"Simple preprocessing function\"\"\"\n",
    "    batch[\"image\"] = [transforms(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# Apply transforms\n",
    "train_ds.set_transform(preprocess)\n",
    "val_ds.set_transform(preprocess)\n",
    "\n",
    "print(\"âœ… Simple preprocessing setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae44bd2-527c-431f-a095-e007eee04889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Setting up simple model...\n",
      "âœ… Labels: {0: 'american', 1: 'chinese', 2: 'french', 3: 'international', 4: 'italian', 5: 'japanese', 6: 'mediterranean', 7: 'mexican'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c2463ffa904423adac16bb64b7d770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562b98187b494e31b3e3d00ae5d24413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([8, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded with 8 classes\n"
     ]
    }
   ],
   "source": [
    "# Simple model setup - no complex wrappers\n",
    "print(\"ğŸ§  Setting up simple model...\")\n",
    "\n",
    "# Create simple label mappings\n",
    "unique_labels = sorted(set(dataset['label']))\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "print(f\"âœ… Labels: {id2label}\")\n",
    "\n",
    "# Load model - simple and direct\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model loaded with {num_labels} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38f41cb8-f77b-43c1-aa77-c8e7703d7189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‹ï¸ Starting simple training...\n",
      "ğŸ”„ MLflow run: 8cd6515b2c234a74a3b20d33448bed25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/accelerate/state.py:261: UserWarning: OMP_NUM_THREADS/MKL_NUM_THREADS unset, we set it at 4 to improve oob performance.\n",
      "  warnings.warn(\n",
      "/root/.ipykernel/1397/command-5371756412541010-2181546381:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[rank0]:[W1110 09:43:33.286950767 reducer.cpp:1430] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='321' max='321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [321/321 09:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.049300</td>\n",
       "      <td>2.027872</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.101408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.953300</td>\n",
       "      <td>2.013881</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.102548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.977800</td>\n",
       "      <td>2.017588</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.102548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training completed!\n",
      "ğŸ“Š Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final metrics: {'eval_loss': 2.013880968093872, 'eval_accuracy': 0.2535211267605634, 'eval_f1': 0.10254787149865484, 'eval_runtime': 10.1883, 'eval_samples_per_second': 20.906, 'eval_steps_per_second': 2.65, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Simple training - no complex custom trainers\n",
    "print(\"ğŸ‹ï¸ Starting simple training...\")\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"ğŸ”„ MLflow run: {run.info.run_id}\")\n",
    "    \n",
    "    # Simple training arguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"/dbfs/tmp/cuisine-classifier-simple\",\n",
    "        remove_unused_columns=False,\n",
    "        eval_strategy=\"epoch\",  # Fixed: was evaluation_strategy\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        logging_steps=10,\n",
    "        report_to=[]\n",
    "    )\n",
    "    \n",
    "    # Simple data collator - like reference\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([e[\"image\"] for e in examples])\n",
    "        labels = torch.tensor([label2id[e[\"label\"]] for e in examples], dtype=torch.long)\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    \n",
    "    # Simple metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "        return {'accuracy': accuracy, 'f1': f1}\n",
    "    \n",
    "    # Simple trainer - standard Transformers\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        train_dataset=train_ds, \n",
    "        eval_dataset=val_ds, \n",
    "        tokenizer=image_processor, \n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"ğŸš€ Training started...\")\n",
    "    trainer.train()\n",
    "    print(\"âœ… Training completed!\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"ğŸ“Š Evaluating model...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"âœ… Final metrics: {eval_results}\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_checkpoint\", MODEL_CHECKPOINT)\n",
    "    mlflow.log_param(\"num_epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"num_labels\", num_labels)\n",
    "    \n",
    "    # Log metrics\n",
    "    for key, value in eval_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            mlflow.log_metric(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2620520-0694-49fb-af2f-1e2ea07c5381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Creating simple model wrapper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple model wrapper created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "# Simple model wrapper for MLflow - like reference\n",
    "print(\"ğŸ“¦ Creating simple model wrapper...\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create pipeline from trained model\n",
    "classifier = pipeline(\n",
    "    \"image-classification\", \n",
    "    model=trainer.model, \n",
    "    feature_extractor=image_processor\n",
    ")\n",
    "\n",
    "class SimpleCuisineClassifier(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Simple wrapper for cuisine classification - like reference notebook\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.pipeline.model.eval()\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"Simple prediction method\"\"\"\n",
    "        # Handle DataFrame input\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            # Convert bytes to PIL images\n",
    "            images = model_input['processed_image_data'].apply(\n",
    "                lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "            ).tolist()\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions = self.pipeline(images)\n",
    "            \n",
    "            # Return top prediction for each image\n",
    "            return pd.DataFrame([\n",
    "                max(pred, key=lambda x: x['score']) \n",
    "                for pred in predictions\n",
    "            ])\n",
    "        \n",
    "        # Handle single image bytes\n",
    "        else:\n",
    "            image = Image.open(io.BytesIO(model_input)).convert(\"RGB\")\n",
    "            with torch.no_grad():\n",
    "                prediction = self.pipeline(image)\n",
    "            return max(prediction, key=lambda x: x['score'])\n",
    "\n",
    "# Create wrapped model\n",
    "wrapped_model = SimpleCuisineClassifier(classifier)\n",
    "print(\"âœ… Simple model wrapper created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c7f221-819e-4494-a5d8-ad556693d21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Logging model to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 09:59:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test predictions:       label     score\n",
      "0  american  0.172005\n",
      "1  american  0.196499\n",
      "2  american  0.173358\n",
      "âœ… Model signature created: inputs: \n",
      "  ['processed_image_data': binary (required)]\n",
      "outputs: \n",
      "  ['label': string (required), 'score': double (required)]\n",
      "params: \n",
      "  None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”— View Logged Model at: https://adb-2867553723712000.0.azuredatabricks.net/ml/experiments/2328462332528265/models/m-7054c1d213f7468cb7dfc192bbf3fe68?o=2867553723712000\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-ffb1dc2b-b5b2-40ac-b3e7-a6c42bab013c/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3285: UserWarning: \u001b[1;33mAn input example was not provided when logging the model. To ensure the model signature functions correctly, specify the `input_example` parameter. See https://mlflow.org/docs/latest/model/signatures.html#model-input-example for more details about the benefits of using input_example.\u001b[0m\n",
      "  color_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model logged with signature: models:/m-7054c1d213f7468cb7dfc192bbf3fe68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'cuisine_vision_catalog.ml_models.cuisine_classifier_simple' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe27883a3804306a836ad1838a1edee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38e2cf074f4a56bead52902e10bbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”— Created version '1' of model 'cuisine_vision_catalog.ml_models.cuisine_classifier_simple': https://adb-2867553723712000.0.azuredatabricks.net/explore/data/models/cuisine_vision_catalog/ml_models/cuisine_classifier_simple/version/1?o=2867553723712000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ Model registered successfully!\n",
      "   ğŸ“¦ Model: cuisine_vision_catalog.ml_models.cuisine_classifier_simple\n",
      "   ğŸ·ï¸ Version: 1\n",
      "   ğŸ¯ Approach: Simple & Reliable\n"
     ]
    }
   ],
   "source": [
    "# Simple MLflow logging and registration\n",
    "print(\"ğŸ“Š Logging model to MLflow...\")\n",
    "\n",
    "# Import signature utilities\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    # Test model with sample data and create signature\n",
    "    test_df = dataset_df[['processed_image_data']].head(3)\n",
    "    test_predictions = wrapped_model.predict(None, test_df)\n",
    "    print(f\"âœ… Test predictions: {test_predictions}\")\n",
    "    \n",
    "    # Create model signature - required for Unity Catalog\n",
    "    signature = infer_signature(test_df, test_predictions)\n",
    "    print(f\"âœ… Model signature created: {signature}\")\n",
    "    \n",
    "    # Log model with signature - required for Unity Catalog\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=wrapped_model,\n",
    "        signature=signature,  # Added signature for Unity Catalog\n",
    "        pip_requirements=[\n",
    "            \"torch\", \n",
    "            \"transformers\", \n",
    "            \"pillow\", \n",
    "            \"pandas\",\n",
    "            \"numpy\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Model logged with signature: {model_info.model_uri}\")\n",
    "\n",
    "# Register to Unity Catalog - simple registration\n",
    "full_model_name = f\"{CATALOG}.ml_models.cuisine_classifier_simple\"\n",
    "registered_model = mlflow.register_model(\n",
    "    model_uri=model_info.model_uri, \n",
    "    name=full_model_name,\n",
    "    tags={\n",
    "        \"stage\": \"development\",\n",
    "        \"task\": \"image_classification\",\n",
    "        \"architecture\": \"ResNet-50\",\n",
    "        \"approach\": \"simple\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"ğŸ‰ Model registered successfully!\")\n",
    "print(f\"   ğŸ“¦ Model: {full_model_name}\")\n",
    "print(f\"   ğŸ·ï¸ Version: {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16601f9-746d-40f0-9040-48396a0ec995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Final testing...\n",
      "Sample 31:\n",
      "   âœ… True: american\n",
      "   ğŸ¯ Predicted: american (score: 0.209)\n",
      "\n",
      "Sample 832:\n",
      "   âœ… True: japanese\n",
      "   ğŸ¯ Predicted: american (score: 0.170)\n",
      "\n",
      "Sample 413:\n",
      "   âœ… True: french\n",
      "   ğŸ¯ Predicted: american (score: 0.169)\n",
      "\n",
      "ğŸ‰ Simple pipeline completed successfully!\n",
      "\n",
      "ğŸ“‹ Summary:\n",
      "   ğŸ“Š Total samples: 1065\n",
      "   ğŸ·ï¸ Classes: 8\n",
      "   ğŸ”„ Epochs: 3\n",
      "   ğŸ“¦ Model: cuisine_vision_catalog.ml_models.cuisine_classifier_simple v1\n",
      "   ğŸ’¡ Approach: Clean, simple, and reliable!\n"
     ]
    }
   ],
   "source": [
    "# Simple testing - verify everything works\n",
    "print(\"ğŸ§ª Final testing...\")\n",
    "\n",
    "# Test with a few samples\n",
    "test_samples = dataset_df.sample(n=3)\n",
    "for idx, row in test_samples.iterrows():\n",
    "    true_label = row['cuisine_category']\n",
    "    image_bytes = row['processed_image_data']\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = wrapped_model.predict(None, image_bytes)\n",
    "    \n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"   âœ… True: {true_label}\")\n",
    "    print(f\"   ğŸ¯ Predicted: {prediction['label']} (score: {prediction['score']:.3f})\")\n",
    "    print()\n",
    "\n",
    "print(\"ğŸ‰ Simple pipeline completed successfully!\")\n",
    "print(\"\\nğŸ“‹ Summary:\")\n",
    "print(f\"   ğŸ“Š Total samples: {len(dataset_df)}\")\n",
    "print(f\"   ğŸ·ï¸ Classes: {num_labels}\")\n",
    "print(f\"   ğŸ”„ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   ğŸ“¦ Model: {full_model_name} v{registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Model Performance Diagnostics\n",
    "\n",
    "Let's analyze why the model might not be predicting accurately by examining the dataset and training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Analysis - Check for common issues\n",
    "print(\"ğŸ” Dataset Analysis:\")\n",
    "print(f\"ğŸ“Š Total samples: {len(dataset_df)}\")\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = dataset_df['cuisine_category'].value_counts()\n",
    "print(f\"\\nğŸ½ï¸ Class Distribution:\")\n",
    "for cuisine, count in class_counts.items():\n",
    "    percentage = (count / len(dataset_df)) * 100\n",
    "    print(f\"   {cuisine}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Check for class imbalance\n",
    "min_samples = class_counts.min()\n",
    "max_samples = class_counts.max()\n",
    "imbalance_ratio = max_samples / min_samples\n",
    "print(f\"\\nâš–ï¸ Class Imbalance Analysis:\")\n",
    "print(f\"   Min class size: {min_samples} samples\")\n",
    "print(f\"   Max class size: {max_samples} samples\") \n",
    "print(f\"   Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "\n",
    "# Identify potential issues\n",
    "print(f\"\\nâš ï¸ Potential Issues Detected:\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"   ğŸš¨ SIGNIFICANT CLASS IMBALANCE! Some classes have 3x+ more samples than others\")\n",
    "    print(\"      â†’ Solution: Use class weights or data augmentation\")\n",
    "\n",
    "if min_samples < 50:\n",
    "    print(\"   ğŸš¨ VERY SMALL DATASET! Some classes have <50 samples\")\n",
    "    print(\"      â†’ Solution: Collect more data or use data augmentation\")\n",
    "\n",
    "if len(dataset_df) < 500:\n",
    "    print(\"   ğŸš¨ SMALL TOTAL DATASET! Less than 500 samples for deep learning\")\n",
    "    print(\"      â†’ Solution: Collect significantly more data\")\n",
    "\n",
    "if max_samples > 5 * min_samples:\n",
    "    print(\"   ğŸš¨ EXTREME IMBALANCE! Majority class dominates\")\n",
    "    print(\"      â†’ Solution: Balance dataset or use stratified sampling\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Recommendations:\")\n",
    "print(f\"   â€¢ Ideal dataset size: 1000+ samples per class\")\n",
    "print(f\"   â€¢ Current average: {len(dataset_df) / num_labels:.0f} samples per class\")\n",
    "print(f\"   â€¢ Minimum recommended: 200+ samples per class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Performance Analysis\n",
    "print(\"ğŸ“Š Training Performance Analysis:\")\n",
    "\n",
    "# Analyze final training metrics\n",
    "if 'eval_results' in locals():\n",
    "    print(\"\\nâœ… Final Evaluation Metrics:\")\n",
    "    for metric, value in eval_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Interpret the metrics\n",
    "    eval_acc = eval_results.get('eval_accuracy', 0)\n",
    "    eval_loss = eval_results.get('eval_loss', float('inf'))\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Performance Interpretation:\")\n",
    "    if eval_acc < 0.3:\n",
    "        print(\"   ğŸ”´ CRITICAL: Very low accuracy (<30%) - model is barely learning\")\n",
    "        print(\"      â†’ Likely causes: insufficient data, too few epochs, or data quality issues\")\n",
    "    elif eval_acc < 0.5:\n",
    "        print(\"   ğŸŸ¡ POOR: Low accuracy (<50%) - significant improvement needed\")\n",
    "        print(\"      â†’ Likely causes: class imbalance, insufficient training, or weak features\")\n",
    "    elif eval_acc < 0.7:\n",
    "        print(\"   ğŸŸ  FAIR: Moderate accuracy (<70%) - room for improvement\")\n",
    "        print(\"      â†’ Solutions: more training, data augmentation, or hyperparameter tuning\")\n",
    "    elif eval_acc < 0.85:\n",
    "        print(\"   ğŸŸ¢ GOOD: Solid accuracy (70-85%) - decent performance\")\n",
    "        print(\"      â†’ Can improve with more data or fine-tuning\")\n",
    "    else:\n",
    "        print(\"   ğŸŸ¢ EXCELLENT: High accuracy (>85%) - great performance!\")\n",
    "        \n",
    "    if eval_loss > 2.0:\n",
    "        print(\"   âš ï¸ High validation loss - model may be underfitting\")\n",
    "    elif eval_loss < 0.1:\n",
    "        print(\"   âš ï¸ Very low validation loss - check for overfitting\")\n",
    "\n",
    "# Extended prediction accuracy test\n",
    "print(f\"\\nğŸ¯ Extended Prediction Accuracy Test:\")\n",
    "test_size = min(50, len(dataset_df))  # Test on up to 50 samples\n",
    "test_larger = dataset_df.sample(n=test_size, random_state=42)\n",
    "correct = 0\n",
    "total = len(test_larger)\n",
    "cuisine_correct = {cuisine: 0 for cuisine in dataset_df['cuisine_category'].unique()}\n",
    "cuisine_total = {cuisine: 0 for cuisine in dataset_df['cuisine_category'].unique()}\n",
    "\n",
    "print(f\"Testing on {total} random samples...\")\n",
    "\n",
    "for idx, row in test_larger.iterrows():\n",
    "    true_label = row['cuisine_category']\n",
    "    prediction = wrapped_model.predict(None, row['processed_image_data'])\n",
    "    predicted_label = prediction['label']\n",
    "    confidence = prediction['score']\n",
    "    \n",
    "    cuisine_total[true_label] += 1\n",
    "    \n",
    "    if true_label == predicted_label:\n",
    "        correct += 1\n",
    "        cuisine_correct[true_label] += 1\n",
    "        status = \"âœ…\"\n",
    "    else:\n",
    "        status = \"âŒ\"\n",
    "    \n",
    "    if idx < 10:  # Show first 10 predictions\n",
    "        print(f\"   {status} True: {true_label:<15} | Predicted: {predicted_label:<15} | Confidence: {confidence:.3f}\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = correct / total\n",
    "print(f\"\\nğŸ“ˆ Overall Test Accuracy: {overall_accuracy:.1%} ({correct}/{total})\")\n",
    "\n",
    "# Per-class accuracy\n",
    "print(f\"\\nğŸ“Š Per-Class Accuracy:\")\n",
    "for cuisine in sorted(cuisine_total.keys()):\n",
    "    if cuisine_total[cuisine] > 0:\n",
    "        class_acc = cuisine_correct[cuisine] / cuisine_total[cuisine]\n",
    "        print(f\"   {cuisine:<15}: {class_acc:.1%} ({cuisine_correct[cuisine]}/{cuisine_total[cuisine]})\")\n",
    "    else:\n",
    "        print(f\"   {cuisine:<15}: No samples in test set\")\n",
    "\n",
    "# Identify problematic classes\n",
    "print(f\"\\nğŸš¨ Classes with Low Accuracy (<50%):\")\n",
    "problem_classes = []\n",
    "for cuisine in cuisine_total.keys():\n",
    "    if cuisine_total[cuisine] > 0:\n",
    "        class_acc = cuisine_correct[cuisine] / cuisine_total[cuisine]\n",
    "        if class_acc < 0.5:\n",
    "            problem_classes.append(f\"{cuisine} ({class_acc:.1%})\")\n",
    "\n",
    "if problem_classes:\n",
    "    for problem in problem_classes:\n",
    "        print(f\"   â€¢ {problem}\")\n",
    "    print(f\"\\nğŸ’¡ Focus improvement efforts on these classes!\")\n",
    "else:\n",
    "    print(\"   ğŸ‰ All classes performing reasonably well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement Recommendations Based on Analysis\n",
    "print(\"ğŸš€ Improvement Recommendations:\")\n",
    "\n",
    "# Get current metrics for recommendations\n",
    "current_accuracy = eval_results.get('eval_accuracy', 0) if 'eval_results' in locals() else 0\n",
    "dataset_size = len(dataset_df)\n",
    "min_class_size = class_counts.min()\n",
    "max_class_size = class_counts.max()\n",
    "\n",
    "print(f\"\\nğŸ“‹ Priority Actions (implement in order):\")\n",
    "\n",
    "# Priority 1: Data quantity issues\n",
    "if dataset_size < 1000:\n",
    "    print(f\"   ğŸ”´ CRITICAL - Collect more data:\")\n",
    "    print(f\"      Current: {dataset_size} samples | Target: 1000+ samples\")\n",
    "    print(f\"      Need: {1000 - dataset_size} more samples\")\n",
    "\n",
    "if min_class_size < 100:\n",
    "    print(f\"   ğŸ”´ CRITICAL - Balance dataset:\")\n",
    "    print(f\"      Smallest class: {min_class_size} samples | Target: 100+ per class\")\n",
    "    print(f\"      Focus on collecting data for: {class_counts.idxmin()}\")\n",
    "\n",
    "# Priority 2: Training configuration\n",
    "if current_accuracy < 0.6:\n",
    "    print(f\"   ğŸŸ¡ HIGH - Improve training:\")\n",
    "    print(f\"      â€¢ Increase epochs: {NUM_EPOCHS} â†’ 10-15 epochs\")\n",
    "    print(f\"      â€¢ Increase learning rate: {LEARNING_RATE} â†’ 2e-4\")\n",
    "    print(f\"      â€¢ Add data augmentation\")\n",
    "    \n",
    "# Priority 3: Model improvements    \n",
    "if imbalance_ratio > 3:\n",
    "    print(f\"   ğŸŸ  MEDIUM - Address class imbalance:\")\n",
    "    print(f\"      â€¢ Use class weights during training\")\n",
    "    print(f\"      â€¢ Apply stratified sampling\")\n",
    "    print(f\"      â€¢ Generate synthetic data for minority classes\")\n",
    "\n",
    "print(f\"\\nğŸ”§ Quick Fixes to Try Next:\")\n",
    "print(f\"   1. Update configuration in cell 5:\")\n",
    "print(f\"      NUM_EPOCHS = 10\")\n",
    "print(f\"      BATCH_SIZE = 16  # if memory allows\")\n",
    "print(f\"      LEARNING_RATE = 2e-4\")\n",
    "\n",
    "print(f\"\\n   2. Add data augmentation in cell 7:\")\n",
    "print(f\"      from torchvision.transforms import RandomHorizontalFlip, ColorJitter\")\n",
    "print(f\"      # Add to transforms: RandomHorizontalFlip(p=0.5), ColorJitter(...)\")\n",
    "\n",
    "print(f\"\\n   3. Consider using a different model:\")\n",
    "print(f\"      MODEL_CHECKPOINT = 'google/vit-base-patch16-224'  # Vision Transformer\")\n",
    "print(f\"      # or\")\n",
    "print(f\"      MODEL_CHECKPOINT = 'microsoft/swin-tiny-patch4-window7-224'  # Swin Transformer\")\n",
    "\n",
    "# Expected improvement\n",
    "print(f\"\\nğŸ“ˆ Expected Improvements:\")\n",
    "if dataset_size < 500:\n",
    "    print(f\"   â€¢ With 2-3x more data: +15-25% accuracy\")\n",
    "if NUM_EPOCHS == 3:\n",
    "    print(f\"   â€¢ With 10 epochs: +5-15% accuracy\") \n",
    "if min_class_size < 50:\n",
    "    print(f\"   â€¢ With balanced classes: +10-20% accuracy\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Realistic Targets:\")\n",
    "if dataset_size < 500:\n",
    "    print(f\"   â€¢ Short term: 50-60% accuracy (with current data + better training)\")\n",
    "    print(f\"   â€¢ Long term: 75-85% accuracy (with more balanced data)\")\n",
    "else:\n",
    "    print(f\"   â€¢ Short term: 65-75% accuracy (with better training)\")\n",
    "    print(f\"   â€¢ Long term: 80-90% accuracy (with data augmentation and tuning)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML_Training_Pipeline_Simple",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
