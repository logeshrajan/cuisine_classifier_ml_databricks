{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35dbc446-bc1a-4fc8-90ad-7dffe1f9d1a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cuisine Classification ML Training Pipeline\n",
    "\n",
    "A straightforward ML training pipeline for cuisine classification using ResNet-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a12d807-d7fd-4751-8ffa-33b0cc8ba9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.12/site-packages (2.7.0+cpu)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.12/site-packages (0.22.0+cpu)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.12/site-packages (4.51.3)\nRequirement already satisfied: datasets in /databricks/python3/lib/python3.12/site-packages (3.5.0)\nCollecting mlflow\n  Using cached mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.6.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (4.12.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\nRequirement already satisfied: sympy>=1.13.3 in /databricks/python3/lib/python3.12/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.1.5)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch) (2023.5.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from torchvision) (2.1.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from torchvision) (11.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.12/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.12/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /databricks/python3/lib/python3.12/site-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.12/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /databricks/python3/lib/python3.12/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.12/site-packages (from datasets) (3.11.10)\nCollecting mlflow-skinny==3.6.0 (from mlflow)\n  Using cached mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.6.0 (from mlflow)\n  Using cached mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: Flask<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.2.5)\nRequirement already satisfied: alembic!=1.10.0,<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.16.5)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (43.0.3)\nCollecting docker<8,>=4.0.0 (from mlflow)\n  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow)\n  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: gunicorn<24 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (20.1.0)\nCollecting huey<3,>=2.5.0 (from mlflow)\n  Using cached huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (1.15.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow) (2.0.37)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.49.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.117.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.4)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (2.10.6)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)\n  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.4.2)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.6.0->mlflow) (0.37.0)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (1.17.1)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.4)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.21)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.40.3)\nRequirement already satisfied: starlette<0.49.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.21.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.27.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.14.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /databricks/python3/lib/python3.12/site-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.6.2)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.8)\nUsing cached mlflow-3.6.0-py3-none-any.whl (8.9 MB)\nUsing cached mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\nUsing cached mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\nUsing cached docker-7.1.0-py3-none-any.whl (147 kB)\nUsing cached flask_cors-6.0.1-py3-none-any.whl (13 kB)\nUsing cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nUsing cached huey-2.5.4-py3-none-any.whl (76 kB)\nUsing cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nUsing cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\nUsing cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nInstalling collected packages: huey, python-dotenv, opentelemetry-proto, graphql-relay, graphene, docker, Flask-CORS, mlflow-tracing, mlflow-skinny, mlflow\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 3.0.1\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ac624415-a0a1-4eb9-a828-517beeefa6ec\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-CORS-6.0.1 docker-7.1.0 graphene-3.4.3 graphql-relay-3.2.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-proto-1.38.0 python-dotenv-1.2.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# installation - only what we need\n",
    "%pip install torch torchvision transformers datasets mlflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a70ac9-7b92-4c75-b87c-c7b77bb6a4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2104df8-b767-4836-a237-558658b2e137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 11:31:03.680355: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-11-10 11:31:03.864055: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-11-10 11:31:04.041331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762774264.189205   23896 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762774264.240006   23896 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1762774264.631665   23896 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762774264.631709   23896 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762774264.631712   23896 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1762774264.631715   23896 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-11-10 11:31:04.675085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-10 11:31:10,799] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n[2025-11-10 11:31:10,803] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\ncollect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# imports - clean and minimal\n",
    "import mlflow\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from PIL import Image\n",
    "import io\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Lambda\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"✅ imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4940f3b-d1aa-4780-8f10-64088a367589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Configuration:\n   \uD83D\uDCCA Catalog: cuisine_vision_catalog\n   \uD83E\uDDE0 Model: microsoft/resnet-50\n   \uD83D\uDD04 Epochs: 5\n   \uD83D\uDCE6 Batch Size: 12\n   \uD83D\uDCC8 Learning Rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# configuration - no complex widgets\n",
    "CATALOG = \"cuisine_vision_catalog\"\n",
    "MODEL_CHECKPOINT = \"microsoft/resnet-50\"\n",
    "EXPERIMENT_NAME = \"/cuisine_classifier\"\n",
    "NUM_EPOCHS = 5 # 3\n",
    "BATCH_SIZE = 12 # 8\n",
    "LEARNING_RATE = 2e-4 # 5e-5\n",
    "\n",
    "print(f\"\uD83D\uDD27 Configuration:\")\n",
    "print(f\"   \uD83D\uDCCA Catalog: {CATALOG}\")\n",
    "print(f\"   \uD83E\uDDE0 Model: {MODEL_CHECKPOINT}\")\n",
    "print(f\"   \uD83D\uDD04 Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   \uD83D\uDCE6 Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   \uD83D\uDCC8 Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1abd211-667b-4c89-9177-93bf97619294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Loading data from gold layer...\n✅ Loaded 8875 samples\n   \uD83C\uDF7D️ Cuisines: ['american', 'chinese', 'french', 'international', 'italian', 'japanese', 'mediterranean', 'mexican']\n✅ Data splits:\n   \uD83C\uDFCB️ Training: 7100 samples\n   ✅ Validation: 1775 samples\n"
     ]
    }
   ],
   "source": [
    "# data loading - direct from gold table\n",
    "print(\"\uD83D\uDCCA Loading data from gold layer...\")\n",
    "\n",
    "# Load data directly - no complex joins\n",
    "dataset_df = (\n",
    "    spark.table(f\"{CATALOG}.gold.ml_dataset\")\n",
    "    .select(\"processed_image_data\", \"cuisine_category\")\n",
    "    .filter(\"processed_image_data IS NOT NULL\")\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "print(f\"✅ Loaded {len(dataset_df)} samples\")\n",
    "print(f\"   \uD83C\uDF7D️ Cuisines: {sorted(dataset_df['cuisine_category'].unique())}\")\n",
    "\n",
    "# Create HuggingFace dataset - rename\n",
    "dataset = Dataset.from_pandas(\n",
    "    dataset_df.rename(columns={\n",
    "        \"processed_image_data\": \"image\", \n",
    "        \"cuisine_category\": \"label\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# train/test split\n",
    "splits = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "print(f\"✅ Data splits:\")\n",
    "print(f\"   \uD83C\uDFCB️ Training: {len(train_ds)} samples\")\n",
    "print(f\"   ✅ Validation: {len(val_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7520b2df-02bf-4f5d-b860-f0f2be6f82e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Setting up preprocessing...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ preprocessing setup complete\n"
     ]
    }
   ],
   "source": [
    "# preprocessing - exactly like reference notebook\n",
    "print(\"\uD83D\uDD04 Setting up preprocessing...\")\n",
    "\n",
    "# Load image processor\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "# transform pipeline\n",
    "transforms = Compose([\n",
    "    Lambda(lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "def preprocess(batch):\n",
    "    \"\"\"preprocessing function\"\"\"\n",
    "    batch[\"image\"] = [transforms(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# Apply transforms\n",
    "train_ds.set_transform(preprocess)\n",
    "val_ds.set_transform(preprocess)\n",
    "\n",
    "print(\"✅ preprocessing setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae44bd2-527c-431f-a095-e007eee04889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83E\uDDE0 Setting up model...\n✅ Labels: {0: 'american', 1: 'chinese', 2: 'french', 3: 'international', 4: 'italian', 5: 'japanese', 6: 'mediterranean', 7: 'mexican'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([8, 2048]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded with 8 classes\n"
     ]
    }
   ],
   "source": [
    "# model setup - no complex wrappers\n",
    "print(\"\uD83E\uDDE0 Setting up model...\")\n",
    "\n",
    "# Create label mappings\n",
    "unique_labels = sorted(set(dataset['label']))\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "print(f\"✅ Labels: {id2label}\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Model loaded with {num_labels} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b368b71-0a43-406c-8e1c-7dd90c8e6617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Optimizing training performance...\n   \uD83D\uDDA5️ Training device: cpu\n   \uD83E\uDDF5 CPU threads: 8\n✅ Performance optimizations applied\n"
     ]
    }
   ],
   "source": [
    "# Optimize training performance and eliminate warnings\n",
    "import os\n",
    "\n",
    "print(\"\uD83D\uDD27 Optimizing training performance...\")\n",
    "\n",
    "# Set threading for better CPU utilization\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "os.environ['MKL_NUM_THREADS'] = '8'\n",
    "\n",
    "# Configure PyTorch for optimal performance\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"   \uD83D\uDDA5️ Training device: {device}\")\n",
    "print(f\"   \uD83E\uDDF5 CPU threads: 8\")\n",
    "print(\"✅ Performance optimizations applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38f41cb8-f77b-43c1-aa77-c8e7703d7189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFCB️ Starting training...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 11:31:25 INFO mlflow.tracking.fluent: Experiment with name '/cuisine_classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 MLflow run: bfc6bb0f29964caabefca309111faa45\n\uD83D\uDE80 Training started...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2960' max='2960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2960/2960 2:21:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.598700</td>\n",
       "      <td>1.503981</td>\n",
       "      <td>0.468169</td>\n",
       "      <td>0.444937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.269656</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.531314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.860100</td>\n",
       "      <td>1.199798</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.574303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.716700</td>\n",
       "      <td>1.143764</td>\n",
       "      <td>0.609577</td>\n",
       "      <td>0.601840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>1.156782</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.602023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed!\n\uD83D\uDCCA Evaluating model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='148' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [148/148 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final metrics: {'eval_loss': 1.1437638998031616, 'eval_accuracy': 0.6095774647887324, 'eval_f1': 0.6018402716095184, 'eval_runtime': 94.5246, 'eval_samples_per_second': 18.778, 'eval_steps_per_second': 1.566, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# training - no complex custom trainers\n",
    "print(\"\uD83C\uDFCB️ Starting training...\")\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"\uD83D\uDD04 MLflow run: {run.info.run_id}\")\n",
    "    \n",
    "\n",
    "    # Training arguments\n",
    "\n",
    "    args = TrainingArguments(\n",
    "            output_dir=f\"/dbfs/tmp/cuisine-classifier\",\n",
    "            remove_unused_columns=False,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            per_device_train_batch_size=BATCH_SIZE,\n",
    "            per_device_eval_batch_size=BATCH_SIZE,\n",
    "            num_train_epochs=NUM_EPOCHS,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            logging_steps=10,\n",
    "            report_to=[],\n",
    "            # PERFORMANCE OPTIMIZATIONS:\n",
    "            dataloader_pin_memory=False,  # Fix pin_memory warning\n",
    "            ddp_find_unused_parameters=False,  # Fix DDP warning\n",
    "            use_cpu=not torch.cuda.is_available(),  # Optimize for CPU if no GPU\n",
    "            )\n",
    "    \n",
    "    # args = TrainingArguments(\n",
    "    #     output_dir=f\"/dbfs/tmp/cuisine-classifier\",\n",
    "    #     remove_unused_columns=False,\n",
    "    #     eval_strategy=\"epoch\",  # Fixed: was evaluation_strategy\n",
    "    #     save_strategy=\"epoch\",\n",
    "    #     learning_rate=LEARNING_RATE,\n",
    "    #     per_device_train_batch_size=BATCH_SIZE,\n",
    "    #     per_device_eval_batch_size=BATCH_SIZE,\n",
    "    #     num_train_epochs=NUM_EPOCHS,\n",
    "    #     weight_decay=0.01,\n",
    "    #     load_best_model_at_end=True,\n",
    "    #     metric_for_best_model=\"eval_loss\",\n",
    "    #     logging_steps=10,\n",
    "    #     report_to=[]\n",
    "    # )\n",
    "    \n",
    "    # data collator - like reference\n",
    "    def collate_fn(examples):\n",
    "        pixel_values = torch.stack([e[\"image\"] for e in examples])\n",
    "        labels = torch.tensor([label2id[e[\"label\"]] for e in examples], dtype=torch.long)\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    \n",
    "    # metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "        return {'accuracy': accuracy, 'f1': f1}\n",
    "\n",
    "    # Trainer - standard Transformers - FIXED VERSION\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        train_dataset=train_ds, \n",
    "        eval_dataset=val_ds, \n",
    "        processing_class=image_processor,  # Fixed: use processing_class instead of tokenizer\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    # trainer = Trainer(\n",
    "    #     model=model, \n",
    "    #     args=args, \n",
    "    #     train_dataset=train_ds, \n",
    "    #     eval_dataset=val_ds, \n",
    "    #     tokenizer=image_processor, \n",
    "    #     data_collator=collate_fn,\n",
    "    #     compute_metrics=compute_metrics\n",
    "    # )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\uD83D\uDE80 Training started...\")\n",
    "    trainer.train()\n",
    "    print(\"✅ Training completed!\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\uD83D\uDCCA Evaluating model...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"✅ Final metrics: {eval_results}\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_checkpoint\", MODEL_CHECKPOINT)\n",
    "    mlflow.log_param(\"num_epochs\", NUM_EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"num_labels\", num_labels)\n",
    "    \n",
    "    # Log metrics\n",
    "    for key, value in eval_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            mlflow.log_metric(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2620520-0694-49fb-af2f-1e2ea07c5381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCE6 Creating model wrapper...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model wrapper created\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac624415-a0a1-4eb9-a828-517beeefa6ec/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "# model wrapper for MLflow - like reference\n",
    "print(\"\uD83D\uDCE6 Creating model wrapper...\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create pipeline from trained model\n",
    "classifier = pipeline(\n",
    "    \"image-classification\", \n",
    "    model=trainer.model, \n",
    "    feature_extractor=image_processor\n",
    ")\n",
    "\n",
    "class CuisineClassifier(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"wrapper for cuisine classification - like reference notebook\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.pipeline.model.eval()\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"prediction method\"\"\"\n",
    "        # Handle DataFrame input\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            # Convert bytes to PIL images\n",
    "            images = model_input['processed_image_data'].apply(\n",
    "                lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "            ).tolist()\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions = self.pipeline(images)\n",
    "            \n",
    "            # Return top prediction for each image\n",
    "            return pd.DataFrame([\n",
    "                max(pred, key=lambda x: x['score']) \n",
    "                for pred in predictions\n",
    "            ])\n",
    "        \n",
    "        # Handle single image bytes\n",
    "        else:\n",
    "            image = Image.open(io.BytesIO(model_input)).convert(\"RGB\")\n",
    "            with torch.no_grad():\n",
    "                prediction = self.pipeline(image)\n",
    "            return max(prediction, key=lambda x: x['score'])\n",
    "\n",
    "# Create wrapped model\n",
    "wrapped_model = CuisineClassifier(classifier)\n",
    "print(\"✅ model wrapper created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9c7f221-819e-4494-a5d8-ad556693d21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Logging model to MLflow...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 13:55:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test predictions:       label     score\n0  american  0.959751\n1  american  0.797454\n2  american  0.973709\n✅ Model signature created: inputs: \n  ['processed_image_data': binary (required)]\noutputs: \n  ['label': string (required), 'score': double (required)]\nparams: \n  None\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://adb-2867553723712000.0.azuredatabricks.net/ml/experiments/2328462332528308/models/m-e990b0dff9114f1db39cf293835fd7a0?o=2867553723712000\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-ac624415-a0a1-4eb9-a828-517beeefa6ec/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3285: UserWarning: \u001B[1;33mAn input example was not provided when logging the model. To ensure the model signature functions correctly, specify the `input_example` parameter. See https://mlflow.org/docs/latest/model/signatures.html#model-input-example for more details about the benefits of using input_example.\u001B[0m\n  color_warning(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model logged with signature: models:/m-e990b0dff9114f1db39cf293835fd7a0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'cuisine_vision_catalog.ml_models.cuisine_classifier'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ae8e1b03d94014b4c6bd49395ee32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f3b1f18536419eae108f995e1d4eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '1' of model 'cuisine_vision_catalog.ml_models.cuisine_classifier': https://adb-2867553723712000.0.azuredatabricks.net/explore/data/models/cuisine_vision_catalog/ml_models/cuisine_classifier/version/1?o=2867553723712000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDF89 Model registered successfully!\n   \uD83D\uDCE6 Model: cuisine_vision_catalog.ml_models.cuisine_classifier\n   \uD83C\uDFF7️ Version: 1\n"
     ]
    }
   ],
   "source": [
    "# MLflow logging and registration\n",
    "print(\"\uD83D\uDCCA Logging model to MLflow...\")\n",
    "\n",
    "# Import signature utilities\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    # Test model with sample data and create signature\n",
    "    test_df = dataset_df[['processed_image_data']].head(3)\n",
    "    test_predictions = wrapped_model.predict(None, test_df)\n",
    "    print(f\"✅ Test predictions: {test_predictions}\")\n",
    "    \n",
    "    # Create model signature - required for Unity Catalog\n",
    "    signature = infer_signature(test_df, test_predictions)\n",
    "    print(f\"✅ Model signature created: {signature}\")\n",
    "    \n",
    "    # Log model with signature - required for Unity Catalog\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=wrapped_model,\n",
    "        signature=signature,  # Added signature for Unity Catalog\n",
    "        pip_requirements=[\n",
    "            \"torch\", \n",
    "            \"transformers\", \n",
    "            \"pillow\", \n",
    "            \"pandas\",\n",
    "            \"numpy\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Model logged with signature: {model_info.model_uri}\")\n",
    "\n",
    "# Register to Unity Catalog - registration\n",
    "full_model_name = f\"{CATALOG}.ml_models.cuisine_classifier\"\n",
    "registered_model = mlflow.register_model(\n",
    "    model_uri=model_info.model_uri, \n",
    "    name=full_model_name,\n",
    "    tags={\n",
    "        \"stage\": \"development\",\n",
    "        \"task\": \"image_classification\",\n",
    "        \"architecture\": \"ResNet-50\",\n",
    "        \"approach\": \"simple\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MlflowClient().set_registered_model_alias(\n",
    "    name=full_model_name,\n",
    "    alias=\"complex\",\n",
    "    version=registered_model.version,\n",
    ")\n",
    "\n",
    "print(f\"\uD83C\uDF89 Model registered successfully!\")\n",
    "print(f\"   \uD83D\uDCE6 Model: {full_model_name}\")\n",
    "print(f\"   \uD83C\uDFF7️ Version: {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16601f9-746d-40f0-9040-48396a0ec995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83E\uDDEA Final testing...\nSample 5299:\n   ✅ True: italian\n   \uD83C\uDFAF Predicted: italian (score: 0.968)\n\nSample 5155:\n   ✅ True: international\n   \uD83C\uDFAF Predicted: international (score: 0.676)\n\nSample 8227:\n   ✅ True: mexican\n   \uD83C\uDFAF Predicted: mexican (score: 0.877)\n\nSample 3175:\n   ✅ True: french\n   \uD83C\uDFAF Predicted: french (score: 0.421)\n\n"
     ]
    }
   ],
   "source": [
    "# testing - verify everything works\n",
    "print(\"\uD83E\uDDEA Final testing...\")\n",
    "\n",
    "# Test with a few samples\n",
    "test_samples = dataset_df.sample(n=4)\n",
    "for idx, row in test_samples.iterrows():\n",
    "    true_label = row['cuisine_category']\n",
    "    image_bytes = row['processed_image_data']\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = wrapped_model.predict(None, image_bytes)\n",
    "    \n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"   ✅ True: {true_label}\")\n",
    "    print(f\"   \uD83C\uDFAF Predicted: {prediction['label']} (score: {prediction['score']:.3f})\")\n",
    "    print()\n",
    "\n",
    "# print(\"\uD83C\uDF89 pipeline completed successfully!\")\n",
    "# print(\"\\n\uD83D\uDCCB Summary:\")\n",
    "# print(f\"   \uD83D\uDCCA Total samples: {len(dataset_df)}\")\n",
    "# print(f\"   \uD83C\uDFF7️ Classes: {num_labels}\")\n",
    "# print(f\"   \uD83D\uDD04 Epochs: {NUM_EPOCHS}\")\n",
    "# print(f\"   \uD83D\uDCE6 Model: {full_model_name} v{registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f148277e-0583-4530-8f15-b833bda05f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDCCA Model Performance Diagnostics\n",
    "\n",
    "Let's analyze why the model might not be predicting accurately by examining the dataset and training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d51fc1f-327f-473a-bb5f-fd247db1963f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D Dataset Analysis:\n\uD83D\uDCCA Total samples: 8875\n\n\uD83C\uDF7D️ Class Distribution:\n   american: 2250 samples (25.4%)\n   italian: 1375 samples (15.5%)\n   french: 1250 samples (14.1%)\n   international: 1125 samples (12.7%)\n   mexican: 875 samples (9.9%)\n   japanese: 875 samples (9.9%)\n   chinese: 625 samples (7.0%)\n   mediterranean: 500 samples (5.6%)\n\n⚖️ Class Imbalance Analysis:\n   Min class size: 500 samples\n   Max class size: 2250 samples\n   Imbalance ratio: 4.50x\n\n⚠️ Potential Issues Detected:\n   \uD83D\uDEA8 SIGNIFICANT CLASS IMBALANCE! Some classes have 3x+ more samples than others\n      → Solution: Use class weights or data augmentation\n\n\uD83D\uDCC8 Recommendations:\n   • Ideal dataset size: 1000+ samples per class\n   • Current average: 1109 samples per class\n   • Minimum recommended: 200+ samples per class\n"
     ]
    }
   ],
   "source": [
    "# Dataset Analysis - Check for common issues\n",
    "print(\"\uD83D\uDD0D Dataset Analysis:\")\n",
    "print(f\"\uD83D\uDCCA Total samples: {len(dataset_df)}\")\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = dataset_df['cuisine_category'].value_counts()\n",
    "print(f\"\\n\uD83C\uDF7D️ Class Distribution:\")\n",
    "for cuisine, count in class_counts.items():\n",
    "    percentage = (count / len(dataset_df)) * 100\n",
    "    print(f\"   {cuisine}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Check for class imbalance\n",
    "min_samples = class_counts.min()\n",
    "max_samples = class_counts.max()\n",
    "imbalance_ratio = max_samples / min_samples\n",
    "print(f\"\\n⚖️ Class Imbalance Analysis:\")\n",
    "print(f\"   Min class size: {min_samples} samples\")\n",
    "print(f\"   Max class size: {max_samples} samples\") \n",
    "print(f\"   Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "\n",
    "# Identify potential issues\n",
    "print(f\"\\n⚠️ Potential Issues Detected:\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"   \uD83D\uDEA8 SIGNIFICANT CLASS IMBALANCE! Some classes have 3x+ more samples than others\")\n",
    "    print(\"      → Solution: Use class weights or data augmentation\")\n",
    "\n",
    "if min_samples < 50:\n",
    "    print(\"   \uD83D\uDEA8 VERY SMALL DATASET! Some classes have <50 samples\")\n",
    "    print(\"      → Solution: Collect more data or use data augmentation\")\n",
    "\n",
    "if len(dataset_df) < 500:\n",
    "    print(\"   \uD83D\uDEA8 SMALL TOTAL DATASET! Less than 500 samples for deep learning\")\n",
    "    print(\"      → Solution: Collect significantly more data\")\n",
    "\n",
    "if max_samples > 5 * min_samples:\n",
    "    print(\"   \uD83D\uDEA8 EXTREME IMBALANCE! Majority class dominates\")\n",
    "    print(\"      → Solution: Balance dataset or use stratified sampling\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDCC8 Recommendations:\")\n",
    "print(f\"   • Ideal dataset size: 1000+ samples per class\")\n",
    "print(f\"   • Current average: {len(dataset_df) / num_labels:.0f} samples per class\")\n",
    "print(f\"   • Minimum recommended: 200+ samples per class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8152c043-cb07-4b50-8423-84b7a6f621cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Training Performance Analysis:\n\n✅ Final Evaluation Metrics:\n   eval_loss: 1.1438\n   eval_accuracy: 0.6096\n   eval_f1: 0.6018\n   eval_runtime: 94.5246\n   eval_samples_per_second: 18.7780\n   eval_steps_per_second: 1.5660\n   epoch: 5.0000\n\n\uD83C\uDFAF Performance Interpretation:\n   \uD83D\uDFE0 FAIR: Moderate accuracy (<70%) - room for improvement\n      → Solutions: more training, data augmentation, or hyperparameter tuning\n\n\uD83C\uDFAF Extended Prediction Accuracy Test:\nTesting on 50 random samples...\n\n\uD83D\uDCC8 Overall Test Accuracy: 74.0% (37/50)\n\n\uD83D\uDCCA Per-Class Accuracy:\n   american       : 78.6% (11/14)\n   chinese        : 0.0% (0/1)\n   french         : 28.6% (2/7)\n   international  : 100.0% (7/7)\n   italian        : 100.0% (9/9)\n   japanese       : 50.0% (1/2)\n   mediterranean  : 60.0% (3/5)\n   mexican        : 80.0% (4/5)\n\n\uD83D\uDEA8 Classes with Low Accuracy (<50%):\n   • chinese (0.0%)\n   • french (28.6%)\n\n\uD83D\uDCA1 Focus improvement efforts on these classes!\n"
     ]
    }
   ],
   "source": [
    "# Training Performance Analysis\n",
    "print(\"\uD83D\uDCCA Training Performance Analysis:\")\n",
    "\n",
    "# Analyze final training metrics\n",
    "if 'eval_results' in locals():\n",
    "    print(\"\\n✅ Final Evaluation Metrics:\")\n",
    "    for metric, value in eval_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Interpret the metrics\n",
    "    eval_acc = eval_results.get('eval_accuracy', 0)\n",
    "    eval_loss = eval_results.get('eval_loss', float('inf'))\n",
    "    \n",
    "    print(f\"\\n\uD83C\uDFAF Performance Interpretation:\")\n",
    "    if eval_acc < 0.3:\n",
    "        print(\"   \uD83D\uDD34 CRITICAL: Very low accuracy (<30%) - model is barely learning\")\n",
    "        print(\"      → Likely causes: insufficient data, too few epochs, or data quality issues\")\n",
    "    elif eval_acc < 0.5:\n",
    "        print(\"   \uD83D\uDFE1 POOR: Low accuracy (<50%) - significant improvement needed\")\n",
    "        print(\"      → Likely causes: class imbalance, insufficient training, or weak features\")\n",
    "    elif eval_acc < 0.7:\n",
    "        print(\"   \uD83D\uDFE0 FAIR: Moderate accuracy (<70%) - room for improvement\")\n",
    "        print(\"      → Solutions: more training, data augmentation, or hyperparameter tuning\")\n",
    "    elif eval_acc < 0.85:\n",
    "        print(\"   \uD83D\uDFE2 GOOD: Solid accuracy (70-85%) - decent performance\")\n",
    "        print(\"      → Can improve with more data or fine-tuning\")\n",
    "    else:\n",
    "        print(\"   \uD83D\uDFE2 EXCELLENT: High accuracy (>85%) - great performance!\")\n",
    "        \n",
    "    if eval_loss > 2.0:\n",
    "        print(\"   ⚠️ High validation loss - model may be underfitting\")\n",
    "    elif eval_loss < 0.1:\n",
    "        print(\"   ⚠️ Very low validation loss - check for overfitting\")\n",
    "\n",
    "# Extended prediction accuracy test\n",
    "print(f\"\\n\uD83C\uDFAF Extended Prediction Accuracy Test:\")\n",
    "test_size = min(50, len(dataset_df))  # Test on up to 50 samples\n",
    "test_larger = dataset_df.sample(n=test_size, random_state=42)\n",
    "correct = 0\n",
    "total = len(test_larger)\n",
    "cuisine_correct = {cuisine: 0 for cuisine in dataset_df['cuisine_category'].unique()}\n",
    "cuisine_total = {cuisine: 0 for cuisine in dataset_df['cuisine_category'].unique()}\n",
    "\n",
    "print(f\"Testing on {total} random samples...\")\n",
    "\n",
    "for idx, row in test_larger.iterrows():\n",
    "    true_label = row['cuisine_category']\n",
    "    prediction = wrapped_model.predict(None, row['processed_image_data'])\n",
    "    predicted_label = prediction['label']\n",
    "    confidence = prediction['score']\n",
    "    \n",
    "    cuisine_total[true_label] += 1\n",
    "    \n",
    "    if true_label == predicted_label:\n",
    "        correct += 1\n",
    "        cuisine_correct[true_label] += 1\n",
    "        status = \"✅\"\n",
    "    else:\n",
    "        status = \"❌\"\n",
    "    \n",
    "    if idx < 10:  # Show first 10 predictions\n",
    "        print(f\"   {status} True: {true_label:<15} | Predicted: {predicted_label:<15} | Confidence: {confidence:.3f}\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = correct / total\n",
    "print(f\"\\n\uD83D\uDCC8 Overall Test Accuracy: {overall_accuracy:.1%} ({correct}/{total})\")\n",
    "\n",
    "# Per-class accuracy\n",
    "print(f\"\\n\uD83D\uDCCA Per-Class Accuracy:\")\n",
    "for cuisine in sorted(cuisine_total.keys()):\n",
    "    if cuisine_total[cuisine] > 0:\n",
    "        class_acc = cuisine_correct[cuisine] / cuisine_total[cuisine]\n",
    "        print(f\"   {cuisine:<15}: {class_acc:.1%} ({cuisine_correct[cuisine]}/{cuisine_total[cuisine]})\")\n",
    "    else:\n",
    "        print(f\"   {cuisine:<15}: No samples in test set\")\n",
    "\n",
    "# Identify problematic classes\n",
    "print(f\"\\n\uD83D\uDEA8 Classes with Low Accuracy (<50%):\")\n",
    "problem_classes = []\n",
    "for cuisine in cuisine_total.keys():\n",
    "    if cuisine_total[cuisine] > 0:\n",
    "        class_acc = cuisine_correct[cuisine] / cuisine_total[cuisine]\n",
    "        if class_acc < 0.5:\n",
    "            problem_classes.append(f\"{cuisine} ({class_acc:.1%})\")\n",
    "\n",
    "if problem_classes:\n",
    "    for problem in problem_classes:\n",
    "        print(f\"   • {problem}\")\n",
    "    print(f\"\\n\uD83D\uDCA1 Focus improvement efforts on these classes!\")\n",
    "else:\n",
    "    print(\"   \uD83C\uDF89 All classes performing reasonably well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f40f533-d029-4a5f-a48e-d35208b815ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 Improvement Recommendations:\n\n\uD83D\uDCCB Priority Actions (implement in order):\n   \uD83D\uDFE0 MEDIUM - Address class imbalance:\n      • Use class weights during training\n      • Apply stratified sampling\n      • Generate synthetic data for minority classes\n\n\uD83D\uDD27 Quick Fixes to Try Next:\n   1. Update configuration in cell 5:\n      NUM_EPOCHS = 10\n      BATCH_SIZE = 16  # if memory allows\n      LEARNING_RATE = 2e-4\n\n   2. Add data augmentation in cell 7:\n      from torchvision.transforms import RandomHorizontalFlip, ColorJitter\n      # Add to transforms: RandomHorizontalFlip(p=0.5), ColorJitter(...)\n\n   3. Consider using a different model:\n      MODEL_CHECKPOINT = 'google/vit-base-patch16-224'  # Vision Transformer\n      # or\n      MODEL_CHECKPOINT = 'microsoft/swin-tiny-patch4-window7-224'  # Swin Transformer\n\n\uD83D\uDCC8 Expected Improvements:\n\n\uD83C\uDFAF Realistic Targets:\n   • Short term: 65-75% accuracy (with better training)\n   • Long term: 80-90% accuracy (with data augmentation and tuning)\n"
     ]
    }
   ],
   "source": [
    "# Improvement Recommendations Based on Analysis\n",
    "print(\"\uD83D\uDE80 Improvement Recommendations:\")\n",
    "\n",
    "# Get current metrics for recommendations\n",
    "current_accuracy = eval_results.get('eval_accuracy', 0) if 'eval_results' in locals() else 0\n",
    "dataset_size = len(dataset_df)\n",
    "min_class_size = class_counts.min()\n",
    "max_class_size = class_counts.max()\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCB Priority Actions (implement in order):\")\n",
    "\n",
    "# Priority 1: Data quantity issues\n",
    "if dataset_size < 1000:\n",
    "    print(f\"   \uD83D\uDD34 CRITICAL - Collect more data:\")\n",
    "    print(f\"      Current: {dataset_size} samples | Target: 1000+ samples\")\n",
    "    print(f\"      Need: {1000 - dataset_size} more samples\")\n",
    "\n",
    "if min_class_size < 100:\n",
    "    print(f\"   \uD83D\uDD34 CRITICAL - Balance dataset:\")\n",
    "    print(f\"      Smallest class: {min_class_size} samples | Target: 100+ per class\")\n",
    "    print(f\"      Focus on collecting data for: {class_counts.idxmin()}\")\n",
    "\n",
    "# Priority 2: Training configuration\n",
    "if current_accuracy < 0.6:\n",
    "    print(f\"   \uD83D\uDFE1 HIGH - Improve training:\")\n",
    "    print(f\"      • Increase epochs: {NUM_EPOCHS} → 10-15 epochs\")\n",
    "    print(f\"      • Increase learning rate: {LEARNING_RATE} → 2e-4\")\n",
    "    print(f\"      • Add data augmentation\")\n",
    "    \n",
    "# Priority 3: Model improvements    \n",
    "if imbalance_ratio > 3:\n",
    "    print(f\"   \uD83D\uDFE0 MEDIUM - Address class imbalance:\")\n",
    "    print(f\"      • Use class weights during training\")\n",
    "    print(f\"      • Apply stratified sampling\")\n",
    "    print(f\"      • Generate synthetic data for minority classes\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDD27 Quick Fixes to Try Next:\")\n",
    "print(f\"   1. Update configuration in cell 5:\")\n",
    "print(f\"      NUM_EPOCHS = 10\")\n",
    "print(f\"      BATCH_SIZE = 16  # if memory allows\")\n",
    "print(f\"      LEARNING_RATE = 2e-4\")\n",
    "\n",
    "print(f\"\\n   2. Add data augmentation in cell 7:\")\n",
    "print(f\"      from torchvision.transforms import RandomHorizontalFlip, ColorJitter\")\n",
    "print(f\"      # Add to transforms: RandomHorizontalFlip(p=0.5), ColorJitter(...)\")\n",
    "\n",
    "print(f\"\\n   3. Consider using a different model:\")\n",
    "print(f\"      MODEL_CHECKPOINT = 'google/vit-base-patch16-224'  # Vision Transformer\")\n",
    "print(f\"      # or\")\n",
    "print(f\"      MODEL_CHECKPOINT = 'microsoft/swin-tiny-patch4-window7-224'  # Swin Transformer\")\n",
    "\n",
    "# Expected improvement\n",
    "print(f\"\\n\uD83D\uDCC8 Expected Improvements:\")\n",
    "if dataset_size < 500:\n",
    "    print(f\"   • With 2-3x more data: +15-25% accuracy\")\n",
    "if NUM_EPOCHS == 3:\n",
    "    print(f\"   • With 10 epochs: +5-15% accuracy\") \n",
    "if min_class_size < 50:\n",
    "    print(f\"   • With balanced classes: +10-20% accuracy\")\n",
    "\n",
    "print(f\"\\n\uD83C\uDFAF Realistic Targets:\")\n",
    "if dataset_size < 500:\n",
    "    print(f\"   • Short term: 50-60% accuracy (with current data + better training)\")\n",
    "    print(f\"   • Long term: 75-85% accuracy (with more balanced data)\")\n",
    "else:\n",
    "    print(f\"   • Short term: 65-75% accuracy (with better training)\")\n",
    "    print(f\"   • Long term: 80-90% accuracy (with data augmentation and tuning)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML_Training_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}