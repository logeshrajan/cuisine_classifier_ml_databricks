{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504ea052",
   "metadata": {},
   "source": [
    "# Cuisine Classification - Simple Training Pipeline\n",
    "**Reference-style simple approach for ResNet-50 cuisine classification**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages - matching reference versions\n",
    "%pip install datasets==2.20.0 transformers==4.49.0 accelerate==1.4.0 mlflow==2.20.2 torchvision==0.20.1 torch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5318273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential configuration - parameterized but simple\n",
    "CATALOG = \"cuisine_vision_catalog\"\n",
    "SCHEMA = \"gold\"\n",
    "TABLE_NAME = \"ml_dataset\"\n",
    "MODEL_NAME = \"microsoft/resnet-50\"  # Can switch to: google/vit-base-patch16-224, microsoft/swin-tiny-patch4-window7-224\n",
    "EXPERIMENT_NAME = \"/cuisine_classifier\"\n",
    "REGISTERED_MODEL_NAME = f\"{CATALOG}.ml_models.cuisine_classifier\"\n",
    "NUM_EPOCHS = 5  # Start small like reference\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"üçΩÔ∏è Training {MODEL_NAME} on {CATALOG}.{SCHEMA}.{TABLE_NAME}\")\n",
    "print(f\"üìä Will register as: {REGISTERED_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from gold layer - simple and direct\n",
    "from datasets import Dataset\n",
    "import mlflow\n",
    "\n",
    "# Setup experiment like reference\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Load data directly from gold table - rename columns to match HuggingFace expectations\n",
    "dataset = Dataset.from_spark(\n",
    "    spark.table(f\"{CATALOG}.{SCHEMA}.{TABLE_NAME}\")\n",
    "    .select(\"processed_image_data\", \"cuisine_category\")\n",
    "    .filter(\"processed_image_data IS NOT NULL AND cuisine_category IS NOT NULL\"),\n",
    "    cache_dir=\"/tmp/hf_cache/cuisine_train\"\n",
    ").rename_column(\"processed_image_data\", \"image\").rename_column(\"cuisine_category\", \"label\")\n",
    "\n",
    "# Simple train/test split like reference\n",
    "splits = dataset.train_test_split(test_size=0.2, seed=RANDOM_SEED)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "print(f\"üìä Dataset loaded: {len(train_ds)} train, {len(val_ds)} validation\")\n",
    "print(f\"üè∑Ô∏è Classes: {set(dataset['label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing - exact same pattern as reference\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor\n",
    "from PIL import Image\n",
    "import io\n",
    "from torchvision.transforms import CenterCrop, Compose, Normalize, RandomResizedCrop, Resize, ToTensor, Lambda\n",
    "\n",
    "# Load model feature extractor - same as reference\n",
    "model_def = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Transformations - identical to reference pattern\n",
    "transforms = Compose([\n",
    "    Lambda(lambda b: Image.open(io.BytesIO(b)).convert(\"RGB\")),  # byte to PIL\n",
    "    ToTensor(),  # convert PIL to tensor\n",
    "    Normalize(mean=model_def.image_mean, std=model_def.image_std)\n",
    "])\n",
    "\n",
    "# Preprocessing function - same as reference\n",
    "def preprocess(batch):\n",
    "    \"\"\"Apply transforms across a batch.\"\"\"\n",
    "    batch[\"image\"] = [transforms(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# Set transformations\n",
    "train_ds.set_transform(preprocess)\n",
    "val_ds.set_transform(preprocess)\n",
    "\n",
    "print(f\"üñºÔ∏è Image preprocessing configured for {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup - identical pattern to reference\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# Create label mappings - same logic as reference\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(sorted(set(dataset['label']))):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "print(f\"üè∑Ô∏è Label mapping created: {label2id}\")\n",
    "\n",
    "# Load model - exact same pattern as reference\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    num_labels=len(label2id),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"ü§ñ Model loaded: {MODEL_NAME} with {len(label2id)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments - simplified from reference\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model_short_name = MODEL_NAME.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"/tmp/huggingface/cuisine/{model_short_name}-finetuned\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=8,  # Small batch size for stability\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "print(f\"üèãÔ∏è Training configured: {NUM_EPOCHS} epochs, batch size 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wrapper - simplified from reference\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "class CuisineModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.pipeline.model.eval()\n",
    "\n",
    "    def predict(self, context, images):\n",
    "        from PIL import Image\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Convert bytes to PIL images\n",
    "            if 'processed_image_data' in images.columns:\n",
    "                image_column = 'processed_image_data'\n",
    "            else:\n",
    "                image_column = images.columns[0]  # Fallback to first column\n",
    "                \n",
    "            images_list = images[image_column].apply(lambda b: Image.open(io.BytesIO(b))).to_list()\n",
    "            # Get predictions\n",
    "            predictions = self.pipeline.predict(images_list)\n",
    "            # Return best prediction for each image\n",
    "            return pd.DataFrame([max(r, key=lambda x: x['score']) for r in predictions])\n",
    "\n",
    "print(\"üéØ Model wrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eda8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and MLflow logging - exact reference pattern\n",
    "from transformers import pipeline, Trainer\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "with mlflow.start_run(run_name=f\"cuisine_classifier_{model_short_name}\") as run:\n",
    "    # Log training dataset\n",
    "    mlflow.log_input(mlflow.data.from_huggingface(train_ds, \"training\"))\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"num_classes\": len(label2id),\n",
    "        \"train_size\": len(train_ds),\n",
    "        \"val_size\": len(val_ds)\n",
    "    })\n",
    "\n",
    "    # Data collator - same as reference\n",
    "    def collate_fn(examples):\n",
    "        import torch\n",
    "        pixel_values = torch.stack([e[\"image\"] for e in examples])\n",
    "        labels = torch.tensor([label2id[e[\"label\"]] for e in examples], dtype=torch.long)\n",
    "        labels = torch.nn.functional.one_hot(labels, num_classes=len(label2id)).float()\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "    # Train model\n",
    "    trainer = Trainer(model, args, train_dataset=train_ds, eval_dataset=val_ds, \n",
    "                     tokenizer=model_def, data_collator=collate_fn)\n",
    "    \n",
    "    print(\"üöÄ Starting training...\")\n",
    "    train_results = trainer.train()\n",
    "    print(\"‚úÖ Training completed!\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    classifier = pipeline(\"image-classification\", model=trainer.state.best_model_checkpoint, tokenizer=model_def)\n",
    "    \n",
    "    # Test model and create signature\n",
    "    wrapped_model = CuisineModelWrapper(classifier)\n",
    "    test_df = spark.table(f\"{CATALOG}.{SCHEMA}.{TABLE_NAME}\").select('processed_image_data').limit(5).toPandas()\n",
    "    predictions = wrapped_model.predict(None, test_df)\n",
    "    signature = infer_signature(test_df, predictions)\n",
    "    \n",
    "    # Log model\n",
    "    reqs = mlflow.transformers.get_default_pip_requirements(model)\n",
    "    \n",
    "    logged = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=wrapped_model,\n",
    "        pip_requirements=reqs,\n",
    "        signature=signature,\n",
    "    )\n",
    "    \n",
    "    print(f\"üì¶ Model logged: {logged.model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model registration - same as reference\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "registered = mlflow.register_model(\n",
    "    model_uri=logged.model_uri,\n",
    "    name=REGISTERED_MODEL_NAME,\n",
    ")\n",
    "\n",
    "MlflowClient().set_registered_model_alias(\n",
    "    name=REGISTERED_MODEL_NAME,\n",
    "    alias=\"prod\",\n",
    "    version=registered.version,\n",
    ")\n",
    "\n",
    "print(f\"üéâ Registered {REGISTERED_MODEL_NAME} v{registered.version} and set alias 'prod'.\")\n",
    "print(f\"üîó Model URI: models:/{REGISTERED_MODEL_NAME}@prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test inference - same pattern as reference\n",
    "predict_cuisine_udf = mlflow.pyfunc.spark_udf(spark, model_uri=f\"models:/{REGISTERED_MODEL_NAME}@prod\")\n",
    "columns = predict_cuisine_udf.metadata.get_input_schema().input_names()\n",
    "\n",
    "# Run inference on validation data\n",
    "predictions_df = (\n",
    "    spark.table(f\"{CATALOG}.{SCHEMA}.{TABLE_NAME}\")\n",
    "    .filter(\"dataset_split = 'test'\")\n",
    "    .withColumn(\"prediction\", predict_cuisine_udf(*columns))\n",
    "    .select(\"image_id\", \"cuisine_category\", \"prediction.label as predicted_cuisine\", \"prediction.score\")\n",
    ")\n",
    "\n",
    "display(predictions_df.limit(20))\n",
    "print(\"üß™ Test predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple accuracy check - optional but useful\n",
    "results = predictions_df.selectExpr(\n",
    "    \"cuisine_category as actual\", \n",
    "    \"predicted_cuisine as predicted\", \n",
    "    \"score\"\n",
    ").toPandas()\n",
    "\n",
    "accuracy = (results['actual'] == results['predicted']).mean()\n",
    "print(f\"üéØ Test Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Show per-class results\n",
    "print(\"\\nüìä Per-class results:\")\n",
    "for cuisine in sorted(results['actual'].unique()):\n",
    "    subset = results[results['actual'] == cuisine]\n",
    "    acc = (subset['actual'] == subset['predicted']).mean()\n",
    "    print(f\"   {cuisine}: {acc:.3f} ({len(subset)} samples)\")\n",
    "\n",
    "print(\"\\nüéâ Simple training pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
